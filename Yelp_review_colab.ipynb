{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oegQrR8KwPsC"
      },
      "outputs": [],
      "source": [
        "# all the necessary imports\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, LabelField\n",
        "from torchtext.legacy.data import TabularDataset\n",
        "from torchtext.legacy.data import Iterator, BucketIterator\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Yelp review rating prediction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Millions of people share a great number of reviews about business on [Yelp.com](https://www.yelp.com/) and Yelp mobile app everyday. These reviews and ratings help other users to make a choice. We used [Yelp APIs (application programming interface)](https://www.yelp.ca/developers) to collect over 35,000 reviews of 1,000 restaurants in New York City. We split this dataset into 90\\% TRAIN set (28,000 reviews), 10\\% DEV set (3,500 reviews), and 10\\% TEST set (3,500 reviews). Each review has text review content and a corresponding label (i.e., 5-level rating star). This table shows the class ditribution of TRAIN and DEV sets.\n",
        "\n",
        "|    Rating  |   # of Train   reviews| # of Dev reviews    |  \n",
        "| ---------- | -----------------  |-----|  \n",
        "| 1star      | 5,619              | 683 |  \n",
        "| 2star      | 5,616              | 677 |  \n",
        "| 3star      | 5,583              | 713 |  \n",
        "| 4star      | 5,532              | 733 |  \n",
        "| 5star      | 5,650              | 694 |  \n",
        "\n",
        "\n",
        "In directory `./data/yelp_review/`, we provide the `TRAIN` and `DEV` sets with the corresponding labels.\n",
        "We use the TRAIN and DEV sets to develop a classification system for this task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUkfCJx8BQhR"
      },
      "source": [
        "## Mounting the drive on colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvY1neZY8M4x",
        "outputId": "f12eb6dc-12bf-4545-ffe3-b568b31d4936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5pORj628lKR"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTaItdMt6EAu",
        "outputId": "6de50f39-1670-4169-e5da-4036c339ef6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import string\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "# punctuation = set(string.punctuation)\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    for tok in spacy_en.tokenizer(text):\n",
        "      tokens.append(tok.text)\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PWwVv0vzwn_u"
      },
      "outputs": [],
      "source": [
        "TEXT = Field(sequential=True, tokenize=tokenize_en, lower=False)\n",
        "LABEL = Field(sequential=False, unk_token = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XNFLLFP7wPsF"
      },
      "outputs": [],
      "source": [
        "train,val,_ = TabularDataset.splits(path= \"/yelp/\",train='train.tsv', validation=\"val.tsv\", test=\"test.tsv\", # file names\n",
        "    format='tsv',\n",
        "    skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "    fields=[('tweet', TEXT), ('label', LABEL)])\n",
        "\n",
        "_,_,test = TabularDataset.splits(path= \"/yelp/\",train='train.tsv', validation=\"val.tsv\", test=\"test.tsv\", # file names\n",
        "    format='tsv',\n",
        "    skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "    fields=[('tweet', TEXT)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6se-lHg-wPsG"
      },
      "outputs": [],
      "source": [
        "TEXT.build_vocab(train) # builds vocabulary based on all the words that occur at least twice in the training set\n",
        "LABEL.build_vocab(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UauYILg5wPsG",
        "outputId": "2607e519-e7ea-456b-89d2-060dfc300068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53723\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(len(TEXT.vocab.stoi))\n",
        "print(len(LABEL.vocab.stoi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DubtAGeowPsG",
        "outputId": "9db03e00-28f4-454e-e55c-f6825330d997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'5star': 0, '1star': 1, '2star': 2, '3star': 3, '4star': 4})\n"
          ]
        }
      ],
      "source": [
        "print(LABEL.vocab.stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ic9Im1-cwPsH"
      },
      "outputs": [],
      "source": [
        "#Creating the val, test and train iterators.\n",
        "\n",
        "val_iter = Iterator(\n",
        " dataset = val, # we pass in the datasets we want the iterator to draw data from\n",
        " batch_size= 128,\n",
        " sort_key= None, \n",
        " sort= False,\n",
        "# A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
        " sort_within_batch= False,\n",
        " train= False\n",
        ")\n",
        "\n",
        "\n",
        "test_iter = Iterator(\n",
        " dataset = test, # we pass in the datasets we want the iterator to draw data from\n",
        " batch_size= 128,\n",
        " sort_key= None, \n",
        " sort= False,\n",
        "# A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
        " sort_within_batch= False,\n",
        " train= False\n",
        ")\n",
        "\n",
        "\n",
        "train_iter,_,_ = BucketIterator.splits(\n",
        " (train,val, test), # we pass in the datasets we want the iterator to draw data from\n",
        " batch_sizes= (128,128,128),\n",
        " sort_key=lambda x: len(x.tweet), \n",
        " sort= True,\n",
        "# A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
        " sort_within_batch= True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QyV5HBz9HRW"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "m8wRwqkEwPsH"
      },
      "outputs": [],
      "source": [
        "## GRU model for evaluation.\n",
        "\n",
        "import torch.nn as nn\n",
        "class GRUmodel(nn.Module):\n",
        "  \n",
        "  def __init__(self, embedding_size, vocab_size, output_size, hidden_size, layers):\n",
        "    # In the constructor we define the layers for our model\n",
        "    super(GRUmodel, self).__init__()\n",
        "    # word embedding lookup table\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
        "    # core GRU module\n",
        "    self.GRU_layer = nn.GRU(input_size=embedding_size, hidden_size= hidden_size, num_layers=layers) \n",
        "    # activation function\n",
        "    self.activation_fn = nn.Tanh()\n",
        "    # classification related modules\n",
        "    self.linear_layer = nn.Linear(hidden_size, output_size) \n",
        "    self.softmax_layer = nn.LogSoftmax(dim=1)\n",
        "    self.debug = False\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # In the forward function we define the forward propagation logic\n",
        "    if self.debug:\n",
        "        print(\"input word indices shape = \", x.size())\n",
        "    out = self.embedding(x)\n",
        "    if self.debug:\n",
        "        print(\"word embeddings shape = \", out.size())\n",
        "    out, _ = self.GRU_layer(out) # since we are not feeding h_0 explicitly, h_0 will be initialized to zeros by default\n",
        "    if self.debug:\n",
        "        print(\"RNN output (features from last layer of RNN for all timesteps) shape = \", out.size())\n",
        "    # classify based on the hidden representation after RNN processes the last token\n",
        "    out = out[-1]\n",
        "    if self.debug:\n",
        "        print(\"Tweet embeddings or RNN output (features from last layer of RNN for the last timestep only) shape = \", out.size())\n",
        "    out = self.activation_fn(out)\n",
        "    if self.debug:\n",
        "        print(\"ReLU output shape = \", out.size())\n",
        "    out = self.linear_layer(out)\n",
        "    if self.debug:\n",
        "        print(\"linear layer output shape = \", out.size())\n",
        "    out = self.softmax_layer(out) # accepts 2D or more dimensional inputs\n",
        "    if self.debug:\n",
        "        print(\"softmax layer output shape = \", out.size())\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YGsnVoFZggC_"
      },
      "outputs": [],
      "source": [
        "## Evaluation function\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train(loader,model,criterion,optimizer,device):\n",
        "    total_loss = 0.0\n",
        "    # iterate throught the data loader\n",
        "    num_sample = 0\n",
        "    for batch in loader:\n",
        "        # load the current batch\n",
        "        batch_input = batch.tweet\n",
        "        batch_output = batch.label\n",
        "        \n",
        "        batch_input = batch_input.to(device)\n",
        "        batch_output = batch_output.to(device)\n",
        "        # forward propagation\n",
        "        # pass the data through the model\n",
        "        model_outputs = model(batch_input)\n",
        "        # compute the loss\n",
        "        cur_loss = criterion(model_outputs, batch_output)\n",
        "        total_loss += cur_loss.item()\n",
        "\n",
        "        # backward propagation (compute the gradients and update the model)\n",
        "        # clear the buffer\n",
        "        optimizer.zero_grad()\n",
        "        # compute the gradients\n",
        "        cur_loss.backward()\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        num_sample += batch_output.shape[0]\n",
        "    return total_loss/num_sample\n",
        "\n",
        "# evaluation logic based on classification accuracy\n",
        "def evaluate(loader,model,criterion,device):\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    with torch.no_grad(): # impacts the autograd engine and deactivate it. reduces memory usage and speeds up computation\n",
        "        for batch in loader:\n",
        "             # load the current batch\n",
        "            batch_input = batch.tweet\n",
        "            batch_output = batch.label\n",
        "\n",
        "            batch_input = batch_input.to(device)\n",
        "            # forward propagation\n",
        "            # pass the data through the model\n",
        "            model_outputs = model(batch_input)\n",
        "            # print(model_outputs.shape)\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(model_outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(batch_output)\n",
        "      \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return accuracy,f1score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5OijLLt_otA"
      },
      "source": [
        "# Hyper-parameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0GIyOCHNvrA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# from numpy.lib.histograms import histogramdd\n",
        "# from torch._C import JitType\n",
        "import scipy.stats\n",
        "\n",
        "LEARNING_RATE= 0.1\n",
        "MAX_EPOCHS=10\n",
        "EMBEDDING_SIZE = 300\n",
        "VOCAB_SIZE = len(TEXT.vocab.stoi)\n",
        "NUM_CLASSES = len(LABEL.vocab.stoi)\n",
        "\n",
        "def random_search(hidden_units_list, layers_list):\n",
        "    results = []\n",
        "    for i in layers_list:\n",
        "        for j in hidden_units_list:\n",
        "            config = {\n",
        "                #define hyperparameters here\n",
        "                \"layers\": i,\n",
        "                \"hidden_size\": j\n",
        "                }\n",
        "            print(config)\n",
        "            # model = ConvNet(config[\"layers\"],3,config[\"filters\"],nn.ReLU(),output_size=3, VOCAB_SIZE=VOCAB_SIZE, WORD_VEC_SIZE=WORD_VEC_SIZE)\n",
        "            model = LSTMmodel(EMBEDDING_SIZE, VOCAB_SIZE, NUM_CLASSES, config[\"hidden_size\"], config[\"layers\"]) \n",
        "            model.to(device)\n",
        "            #print﴾model﴿\n",
        "            criterion = nn.NLLLoss()\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "            max_val = 0\n",
        "            best_epoch = 0\n",
        "            for epoch in range(MAX_EPOCHS):\n",
        "                # train the model for one pass over the data\n",
        "                train_loss = train(train_iter,model,criterion,optimizer,device)\n",
        "                # compute the training accuracy\n",
        "                train_acc = evaluate(train_iter,model,criterion,device)\n",
        "                # compute the validation accuracy\n",
        "                val_acc = evaluate(val_iter,model,criterion,device)\n",
        "                if val_acc[0] > max_val:\n",
        "                    max_val = val_acc[0]\n",
        "                    best_epoch = epoch+1\n",
        "                # print the loss for every epoch\n",
        "                print('epoch ',epoch+1,'loss ', train_loss,'Train Accuracy & F1',train_acc,'Validation Accuracy & F1 ', val_acc)\n",
        "                # Append the results for every epoch\n",
        "                results.append((max_val,best_epoch,config))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "loK9BljwNzaX",
        "outputId": "8c32acd1-819c-45f0-8342-42597effd27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'layers': 1, 'hidden_size': 100}\n",
            "epoch  1 loss  0.012513524643012456 Train Accuracy & F1 (0.21967857142857142, 0.1561862096076843) Validation Accuracy & F1  (0.20057142857142857, 0.08284198878417495)\n",
            "epoch  2 loss  0.012396843305655889 Train Accuracy & F1 (0.25292857142857145, 0.21729026335388588) Validation Accuracy & F1  (0.206, 0.09951114433113004)\n",
            "epoch  3 loss  0.012215453054223741 Train Accuracy & F1 (0.27625, 0.2517508151616518) Validation Accuracy & F1  (0.21, 0.11226215087233997)\n",
            "epoch  4 loss  0.011965337663888931 Train Accuracy & F1 (0.30864285714285716, 0.29423468799825697) Validation Accuracy & F1  (0.23285714285714285, 0.15803692391593838)\n",
            "epoch  5 loss  0.011633581097636904 Train Accuracy & F1 (0.3452857142857143, 0.33655521453760784) Validation Accuracy & F1  (0.27485714285714286, 0.23471415949363372)\n",
            "epoch  6 loss  0.01109419098496437 Train Accuracy & F1 (0.38425, 0.37559391462502256) Validation Accuracy & F1  (0.3417142857142857, 0.32342508351012683)\n",
            "epoch  7 loss  0.01055599132180214 Train Accuracy & F1 (0.42442857142857143, 0.40807324952458635) Validation Accuracy & F1  (0.388, 0.3654891574436542)\n",
            "epoch  8 loss  0.010057666399649211 Train Accuracy & F1 (0.3922857142857143, 0.38238080817244297) Validation Accuracy & F1  (0.3605714285714286, 0.3461220793356045)\n",
            "epoch  9 loss  0.00965077644586563 Train Accuracy & F1 (0.4534642857142857, 0.45086267429892) Validation Accuracy & F1  (0.3945714285714286, 0.38668906955756055)\n",
            "epoch  10 loss  0.009271875590085982 Train Accuracy & F1 (0.34575, 0.3083899081214245) Validation Accuracy & F1  (0.28885714285714287, 0.233476286580794)\n",
            "{'layers': 1, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012492878722293037 Train Accuracy & F1 (0.22342857142857142, 0.16699448572833386) Validation Accuracy & F1  (0.20142857142857143, 0.08580083044290802)\n",
            "epoch  2 loss  0.012346918229545865 Train Accuracy & F1 (0.24907142857142858, 0.20979388346238884) Validation Accuracy & F1  (0.2057142857142857, 0.0969380965066772)\n",
            "epoch  3 loss  0.01214130567227091 Train Accuracy & F1 (0.28782142857142856, 0.26650131425197526) Validation Accuracy & F1  (0.21457142857142858, 0.12121778518511513)\n",
            "epoch  4 loss  0.011831137865781783 Train Accuracy & F1 (0.32342857142857145, 0.3059441237740305) Validation Accuracy & F1  (0.23285714285714285, 0.1517175295061412)\n",
            "epoch  5 loss  0.01127754943711417 Train Accuracy & F1 (0.396, 0.3849438624003336) Validation Accuracy & F1  (0.32371428571428573, 0.30519675929348516)\n",
            "epoch  6 loss  0.01070638827766691 Train Accuracy & F1 (0.40485714285714286, 0.3776338822249944) Validation Accuracy & F1  (0.35428571428571426, 0.29053170948217855)\n",
            "epoch  7 loss  0.010293477556535176 Train Accuracy & F1 (0.44042857142857145, 0.42203778691387106) Validation Accuracy & F1  (0.37114285714285716, 0.33254917388572536)\n",
            "epoch  8 loss  0.009911522494895117 Train Accuracy & F1 (0.20557142857142857, 0.07851387149633478) Validation Accuracy & F1  (0.19542857142857142, 0.06623035982230963)\n",
            "epoch  9 loss  0.009783892891236714 Train Accuracy & F1 (0.2757142857142857, 0.20261443463249887) Validation Accuracy & F1  (0.2797142857142857, 0.24221728614926055)\n",
            "epoch  10 loss  0.009302673442023141 Train Accuracy & F1 (0.48296428571428573, 0.45741241972878) Validation Accuracy & F1  (0.42542857142857143, 0.3843365261126223)\n",
            "{'layers': 1, 'hidden_size': 300}\n",
            "epoch  1 loss  0.012486745272363936 Train Accuracy & F1 (0.22446428571428573, 0.1652807287808275) Validation Accuracy & F1  (0.19942857142857143, 0.08102998166268087)\n",
            "epoch  2 loss  0.01234626265508788 Train Accuracy & F1 (0.25460714285714287, 0.2173230766474045) Validation Accuracy & F1  (0.20057142857142857, 0.08809018895795596)\n",
            "epoch  3 loss  0.012129086358206613 Train Accuracy & F1 (0.28167857142857144, 0.24744583093180736) Validation Accuracy & F1  (0.2082857142857143, 0.10207690867434367)\n",
            "epoch  4 loss  0.011773339079959052 Train Accuracy & F1 (0.31264285714285717, 0.2837920049733075) Validation Accuracy & F1  (0.22685714285714287, 0.13497104024068127)\n",
            "epoch  5 loss  0.011105705640145711 Train Accuracy & F1 (0.39925, 0.3713694042823182) Validation Accuracy & F1  (0.31942857142857145, 0.24120677783608055)\n",
            "epoch  6 loss  0.010636793179171426 Train Accuracy & F1 (0.423, 0.3970543276720826) Validation Accuracy & F1  (0.3648571428571429, 0.3016797078953877)\n",
            "epoch  7 loss  0.01029062779034887 Train Accuracy & F1 (0.4217142857142857, 0.38033407032467714) Validation Accuracy & F1  (0.3485714285714286, 0.27050760306530114)\n",
            "epoch  8 loss  0.009930295829262052 Train Accuracy & F1 (0.39717857142857144, 0.36346493202329705) Validation Accuracy & F1  (0.32142857142857145, 0.2708320092718527)\n",
            "epoch  9 loss  0.009535886411155972 Train Accuracy & F1 (0.44092857142857145, 0.42319971824831254) Validation Accuracy & F1  (0.39885714285714285, 0.38064713445798837)\n",
            "epoch  10 loss  0.009262285588043076 Train Accuracy & F1 (0.5051428571428571, 0.47682964470317507) Validation Accuracy & F1  (0.4431428571428571, 0.398205899096023)\n",
            "{'layers': 1, 'hidden_size': 400}\n",
            "epoch  1 loss  0.012477496530328478 Train Accuracy & F1 (0.22739285714285715, 0.17015863655718694) Validation Accuracy & F1  (0.2017142857142857, 0.0860711581010557)\n",
            "epoch  2 loss  0.012309688074248178 Train Accuracy & F1 (0.25107142857142856, 0.21012108510429392) Validation Accuracy & F1  (0.2042857142857143, 0.09384982078322004)\n",
            "epoch  3 loss  0.012084460846015384 Train Accuracy & F1 (0.28710714285714284, 0.25955772860859055) Validation Accuracy & F1  (0.21142857142857144, 0.10860538717799169)\n",
            "epoch  4 loss  0.011631372622081212 Train Accuracy & F1 (0.3598571428571429, 0.33549621408397445) Validation Accuracy & F1  (0.2622857142857143, 0.1878691400781464)\n",
            "epoch  5 loss  0.011049061549561364 Train Accuracy & F1 (0.38075, 0.358633606756044) Validation Accuracy & F1  (0.25885714285714284, 0.1851029828868344)\n",
            "epoch  6 loss  0.010656377668891635 Train Accuracy & F1 (0.41860714285714284, 0.3925274098000917) Validation Accuracy & F1  (0.34514285714285714, 0.27004882534336416)\n",
            "epoch  7 loss  0.010305707667555128 Train Accuracy & F1 (0.4193571428571429, 0.40118327921470975) Validation Accuracy & F1  (0.35514285714285715, 0.32744344666366426)\n",
            "epoch  8 loss  0.0099279146364757 Train Accuracy & F1 (0.4704642857142857, 0.45034885256045254) Validation Accuracy & F1  (0.39085714285714285, 0.3437752915083775)\n",
            "epoch  9 loss  0.009635158347232001 Train Accuracy & F1 (0.4775, 0.44485541214660157) Validation Accuracy & F1  (0.4045714285714286, 0.3710033464231265)\n",
            "epoch  10 loss  0.009405714737517492 Train Accuracy & F1 (0.48110714285714284, 0.45560022717249976) Validation Accuracy & F1  (0.3997142857142857, 0.3630838397266437)\n",
            "{'layers': 1, 'hidden_size': 500}\n",
            "epoch  1 loss  0.012465220889874867 Train Accuracy & F1 (0.2304642857142857, 0.17547288141758627) Validation Accuracy & F1  (0.2002857142857143, 0.0818057805058035)\n",
            "epoch  2 loss  0.012301283504281725 Train Accuracy & F1 (0.25775, 0.22103405820567873) Validation Accuracy & F1  (0.20314285714285715, 0.09132684287406931)\n",
            "epoch  3 loss  0.012059496134519577 Train Accuracy & F1 (0.29164285714285715, 0.2633425203200657) Validation Accuracy & F1  (0.21, 0.10638170040194321)\n",
            "epoch  4 loss  0.011503056751830238 Train Accuracy & F1 (0.37407142857142855, 0.34014353206453574) Validation Accuracy & F1  (0.27685714285714286, 0.19504050841087664)\n",
            "epoch  5 loss  0.010951727956533432 Train Accuracy & F1 (0.38042857142857145, 0.3466835485684426) Validation Accuracy & F1  (0.2782857142857143, 0.21036872513349678)\n",
            "epoch  6 loss  0.010610336576189313 Train Accuracy & F1 (0.39225, 0.36009002116074695) Validation Accuracy & F1  (0.2822857142857143, 0.21456488973339555)\n",
            "epoch  7 loss  0.010299999965088708 Train Accuracy & F1 (0.26807142857142857, 0.19753845504343573) Validation Accuracy & F1  (0.25457142857142856, 0.21124592914620655)\n",
            "epoch  8 loss  0.010033752019916261 Train Accuracy & F1 (0.44960714285714287, 0.4219767685907251) Validation Accuracy & F1  (0.3717142857142857, 0.3068676978595867)\n",
            "epoch  9 loss  0.009720320288624082 Train Accuracy & F1 (0.39925, 0.3494050250215869) Validation Accuracy & F1  (0.3414285714285714, 0.27024953143414115)\n",
            "epoch  10 loss  0.009418051977242742 Train Accuracy & F1 (0.49257142857142855, 0.4701049128852909) Validation Accuracy & F1  (0.4328571428571429, 0.3962980932517612)\n",
            "{'layers': 2, 'hidden_size': 100}\n",
            "epoch  1 loss  0.01253668235880988 Train Accuracy & F1 (0.22039285714285714, 0.1511450802166421) Validation Accuracy & F1  (0.206, 0.10690838881144618)\n",
            "epoch  2 loss  0.012522551830325808 Train Accuracy & F1 (0.23035714285714284, 0.19221987916051275) Validation Accuracy & F1  (0.21085714285714285, 0.1191786687575294)\n",
            "epoch  3 loss  0.012478838205337524 Train Accuracy & F1 (0.24271428571428572, 0.20746342231681952) Validation Accuracy & F1  (0.21057142857142858, 0.12164944944963767)\n",
            "epoch  4 loss  0.012388469074453626 Train Accuracy & F1 (0.26353571428571426, 0.21957390954131212) Validation Accuracy & F1  (0.21828571428571428, 0.13212793462569608)\n",
            "epoch  5 loss  0.012111870203699384 Train Accuracy & F1 (0.2990357142857143, 0.2355412720398479) Validation Accuracy & F1  (0.23885714285714285, 0.15496209903233246)\n",
            "epoch  6 loss  0.011431545278855733 Train Accuracy & F1 (0.35346428571428573, 0.29547526819895314) Validation Accuracy & F1  (0.31657142857142856, 0.2490929919801784)\n",
            "epoch  7 loss  0.011117990463972091 Train Accuracy & F1 (0.32775, 0.27223145703964813) Validation Accuracy & F1  (0.2631428571428571, 0.18825804362737725)\n",
            "epoch  8 loss  0.010768387973308563 Train Accuracy & F1 (0.2509642857142857, 0.19320246112452172) Validation Accuracy & F1  (0.2397142857142857, 0.2171886795657901)\n",
            "epoch  9 loss  0.01041737384881292 Train Accuracy & F1 (0.39682142857142855, 0.39620915054238065) Validation Accuracy & F1  (0.348, 0.328932967885246)\n",
            "epoch  10 loss  0.010589708047253744 Train Accuracy & F1 (0.3269642857142857, 0.287533728755724) Validation Accuracy & F1  (0.286, 0.2363395606528591)\n",
            "{'layers': 2, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012529146841594152 Train Accuracy & F1 (0.22132142857142856, 0.15611888506006705) Validation Accuracy & F1  (0.2022857142857143, 0.09399431097974045)\n",
            "epoch  2 loss  0.01250275896702494 Train Accuracy & F1 (0.23764285714285716, 0.19752496220302143) Validation Accuracy & F1  (0.208, 0.11434247850933851)\n",
            "epoch  3 loss  0.012429985825504575 Train Accuracy & F1 (0.2560357142857143, 0.21857971149776634) Validation Accuracy & F1  (0.21085714285714285, 0.12299464190253288)\n",
            "epoch  4 loss  0.012244478459869113 Train Accuracy & F1 (0.28367857142857145, 0.25250326246235805) Validation Accuracy & F1  (0.22171428571428572, 0.13243222839366536)\n",
            "epoch  5 loss  0.011640315677438463 Train Accuracy & F1 (0.31192857142857144, 0.2776458526174034) Validation Accuracy & F1  (0.23742857142857143, 0.15767315421017464)\n",
            "epoch  6 loss  0.011228897827012198 Train Accuracy & F1 (0.2445, 0.1629175519371201) Validation Accuracy & F1  (0.21285714285714286, 0.10726322295357282)\n",
            "epoch  7 loss  0.010824918180704118 Train Accuracy & F1 (0.40389285714285716, 0.38606104256608303) Validation Accuracy & F1  (0.2977142857142857, 0.2436435292308916)\n",
            "epoch  8 loss  0.01046563099537577 Train Accuracy & F1 (0.4355357142857143, 0.407444565647802) Validation Accuracy & F1  (0.37057142857142855, 0.3280408898340344)\n",
            "epoch  9 loss  0.010077409361089978 Train Accuracy & F1 (0.4617857142857143, 0.4375130641321176) Validation Accuracy & F1  (0.4005714285714286, 0.3593732630917296)\n",
            "epoch  10 loss  0.009867829233407975 Train Accuracy & F1 (0.34539285714285717, 0.28806753674668073) Validation Accuracy & F1  (0.29, 0.22708789493179596)\n",
            "{'layers': 2, 'hidden_size': 300}\n",
            "epoch  1 loss  0.012526416271924972 Train Accuracy & F1 (0.21764285714285714, 0.15091552401713595) Validation Accuracy & F1  (0.20485714285714285, 0.09288027074685357)\n",
            "epoch  2 loss  0.0124920426266534 Train Accuracy & F1 (0.23814285714285716, 0.20040267594896194) Validation Accuracy & F1  (0.206, 0.10813311639891925)\n",
            "epoch  3 loss  0.012396398991346359 Train Accuracy & F1 (0.2568214285714286, 0.2190655361553043) Validation Accuracy & F1  (0.214, 0.12408632697574193)\n",
            "epoch  4 loss  0.012147430070808955 Train Accuracy & F1 (0.29828571428571427, 0.2679831964404867) Validation Accuracy & F1  (0.22542857142857142, 0.14295376677495658)\n",
            "epoch  5 loss  0.01154267505662782 Train Accuracy & F1 (0.3598571428571429, 0.3383864391525312) Validation Accuracy & F1  (0.2742857142857143, 0.21898418302367473)\n",
            "epoch  6 loss  0.0110731614615236 Train Accuracy & F1 (0.20139285714285715, 0.06914263508290949) Validation Accuracy & F1  (0.19542857142857142, 0.0660210673543424)\n",
            "epoch  7 loss  0.012001271333013262 Train Accuracy & F1 (0.3435357142857143, 0.3180613834252203) Validation Accuracy & F1  (0.244, 0.1660136212384807)\n",
            "epoch  8 loss  0.010776455180985587 Train Accuracy & F1 (0.3601785714285714, 0.2960196037383914) Validation Accuracy & F1  (0.308, 0.22130980891904692)\n",
            "epoch  9 loss  0.010433495943035399 Train Accuracy & F1 (0.298, 0.23046319836398368) Validation Accuracy & F1  (0.24628571428571427, 0.16689184347695565)\n",
            "epoch  10 loss  0.010495166940348489 Train Accuracy & F1 (0.3785357142857143, 0.3306931020044003) Validation Accuracy & F1  (0.31314285714285717, 0.2505440515829941)\n",
            "{'layers': 2, 'hidden_size': 400}\n",
            "epoch  1 loss  0.012530302452189581 Train Accuracy & F1 (0.21728571428571428, 0.134355422234805) Validation Accuracy & F1  (0.19942857142857143, 0.07766971037536063)\n",
            "epoch  2 loss  0.012494737527200154 Train Accuracy & F1 (0.23692857142857143, 0.18188699252635107) Validation Accuracy & F1  (0.2057142857142857, 0.10509799954221857)\n",
            "epoch  3 loss  0.012405316076108388 Train Accuracy & F1 (0.2565, 0.21516231426519045) Validation Accuracy & F1  (0.208, 0.11657454331961688)\n",
            "epoch  4 loss  0.01216006727729525 Train Accuracy & F1 (0.30489285714285713, 0.28147754998312713) Validation Accuracy & F1  (0.23314285714285715, 0.15885542085583287)\n",
            "epoch  5 loss  0.011513637976987021 Train Accuracy & F1 (0.35832142857142857, 0.32668399974890194) Validation Accuracy & F1  (0.27171428571428574, 0.2049103650518624)\n",
            "epoch  6 loss  0.011097423378910337 Train Accuracy & F1 (0.29096428571428573, 0.24497729994399356) Validation Accuracy & F1  (0.23942857142857144, 0.17572983802126585)\n",
            "epoch  7 loss  0.010817370495625905 Train Accuracy & F1 (0.40117857142857144, 0.3495461164758916) Validation Accuracy & F1  (0.3357142857142857, 0.2558960483129986)\n",
            "epoch  8 loss  0.010525596099240439 Train Accuracy & F1 (0.30164285714285716, 0.24313905979689676) Validation Accuracy & F1  (0.24371428571428572, 0.1710194558569851)\n",
            "epoch  9 loss  0.01061302502666201 Train Accuracy & F1 (0.3808214285714286, 0.3086152579164386) Validation Accuracy & F1  (0.3417142857142857, 0.26559071785410643)\n",
            "epoch  10 loss  0.010076982702527727 Train Accuracy & F1 (0.24796428571428572, 0.1600858838592162) Validation Accuracy & F1  (0.20485714285714285, 0.08780768017579252)\n",
            "{'layers': 2, 'hidden_size': 500}\n",
            "epoch  1 loss  0.012522905507258007 Train Accuracy & F1 (0.21964285714285714, 0.14267319127221254) Validation Accuracy & F1  (0.2002857142857143, 0.08162843637739745)\n",
            "epoch  2 loss  0.012481373799698693 Train Accuracy & F1 (0.24464285714285713, 0.20477889120893672) Validation Accuracy & F1  (0.20914285714285713, 0.11450654578222982)\n",
            "epoch  3 loss  0.012364057017224176 Train Accuracy & F1 (0.26617857142857143, 0.2270081713610434) Validation Accuracy & F1  (0.21685714285714286, 0.1289229919970363)\n",
            "epoch  4 loss  0.012043704969542367 Train Accuracy & F1 (0.31142857142857144, 0.2860685047205328) Validation Accuracy & F1  (0.238, 0.16271414646609958)\n",
            "epoch  5 loss  0.011409429503338677 Train Accuracy & F1 (0.35960714285714285, 0.3227002724509068) Validation Accuracy & F1  (0.31885714285714284, 0.2521786573439325)\n",
            "epoch  6 loss  0.010991429941994804 Train Accuracy & F1 (0.39353571428571427, 0.36566375727594974) Validation Accuracy & F1  (0.33285714285714285, 0.2735567734646157)\n",
            "epoch  7 loss  0.010642312364918844 Train Accuracy & F1 (0.39417857142857143, 0.36322117672697957) Validation Accuracy & F1  (0.3362857142857143, 0.282224453918242)\n",
            "epoch  8 loss  0.01042285914506231 Train Accuracy & F1 (0.4157142857142857, 0.3847902580655173) Validation Accuracy & F1  (0.35628571428571426, 0.31611509616689937)\n",
            "epoch  9 loss  0.010161884380238398 Train Accuracy & F1 (0.3505, 0.29506645224900785) Validation Accuracy & F1  (0.2837142857142857, 0.2077357010479906)\n",
            "epoch  10 loss  0.00991751937355314 Train Accuracy & F1 (0.3736785714285714, 0.3459212149628917) Validation Accuracy & F1  (0.288, 0.23033682002663508)\n",
            "{'layers': 3, 'hidden_size': 100}\n",
            "epoch  1 loss  0.01255091764671462 Train Accuracy & F1 (0.20057142857142857, 0.06682532127558305) Validation Accuracy & F1  (0.19342857142857142, 0.06483121857792673)\n",
            "epoch  2 loss  0.012563035317829678 Train Accuracy & F1 (0.20057142857142857, 0.06682532127558305) Validation Accuracy & F1  (0.19342857142857142, 0.06483121857792673)\n",
            "epoch  3 loss  0.012559318265744617 Train Accuracy & F1 (0.20060714285714284, 0.06709955381418867) Validation Accuracy & F1  (0.19342857142857142, 0.06483121857792673)\n",
            "epoch  4 loss  0.012554478747504098 Train Accuracy & F1 (0.2030357142857143, 0.08705020541332581) Validation Accuracy & F1  (0.19285714285714287, 0.11041441101282704)\n",
            "epoch  5 loss  0.012547531523874828 Train Accuracy & F1 (0.20557142857142857, 0.09872819637986509) Validation Accuracy & F1  (0.19485714285714287, 0.11283757447007885)\n",
            "epoch  6 loss  0.012536703833511898 Train Accuracy & F1 (0.21482142857142858, 0.14462284113453558) Validation Accuracy & F1  (0.19657142857142856, 0.1206132974242261)\n",
            "epoch  7 loss  0.0125184254859175 Train Accuracy & F1 (0.22421428571428573, 0.1623105532823242) Validation Accuracy & F1  (0.20514285714285715, 0.13739549629367065)\n",
            "epoch  8 loss  0.012484078947986876 Train Accuracy & F1 (0.23342857142857143, 0.18041792778240623) Validation Accuracy & F1  (0.20542857142857143, 0.13699060131322024)\n",
            "epoch  9 loss  0.012413067838975361 Train Accuracy & F1 (0.2561785714285714, 0.21347855709146604) Validation Accuracy & F1  (0.21828571428571428, 0.1496995076048)\n",
            "epoch  10 loss  0.012234670775277274 Train Accuracy & F1 (0.2948571428571429, 0.2713197181030165) Validation Accuracy & F1  (0.23085714285714284, 0.1697524954740339)\n",
            "{'layers': 3, 'hidden_size': 200}\n",
            "epoch  1 loss  0.01254751459615571 Train Accuracy & F1 (0.20057142857142857, 0.06682532127558305) Validation Accuracy & F1  (0.19342857142857142, 0.06483121857792673)\n",
            "epoch  2 loss  0.012557950973510743 Train Accuracy & F1 (0.20057142857142857, 0.06682532127558305) Validation Accuracy & F1  (0.19342857142857142, 0.06483121857792673)\n",
            "epoch  3 loss  0.012548199006489345 Train Accuracy & F1 (0.20210714285714285, 0.08809085668436292) Validation Accuracy & F1  (0.19057142857142856, 0.10986686719840155)\n",
            "epoch  4 loss  0.012529944415603365 Train Accuracy & F1 (0.2269642857142857, 0.17480424569980052) Validation Accuracy & F1  (0.19714285714285715, 0.12440459380568351)\n",
            "epoch  5 loss  0.012482413168464388 Train Accuracy & F1 (0.24878571428571428, 0.2105889903503738) Validation Accuracy & F1  (0.21057142857142858, 0.14979289393540446)\n",
            "epoch  6 loss  0.012267231583595276 Train Accuracy & F1 (0.28532142857142856, 0.25227608196419454) Validation Accuracy & F1  (0.2337142857142857, 0.1786755664585941)\n",
            "epoch  7 loss  0.011663336753845215 Train Accuracy & F1 (0.31971428571428573, 0.25676811436464064) Validation Accuracy & F1  (0.2745714285714286, 0.20053685122598003)\n",
            "epoch  8 loss  0.011338386816637857 Train Accuracy & F1 (0.25085714285714283, 0.1593546343686953) Validation Accuracy & F1  (0.21914285714285714, 0.11232933169568757)\n",
            "epoch  9 loss  0.011029958520616804 Train Accuracy & F1 (0.3628571428571429, 0.3016348524239632) Validation Accuracy & F1  (0.3485714285714286, 0.2729705298305709)\n",
            "epoch  10 loss  0.010847347055162703 Train Accuracy & F1 (0.20067857142857143, 0.06685505220262351) Validation Accuracy & F1  (0.19514285714285715, 0.06531197704996414)\n",
            "{'layers': 3, 'hidden_size': 300}\n",
            "epoch  1 loss  0.01254470065661839 Train Accuracy & F1 (0.20075, 0.06752236984435125) Validation Accuracy & F1  (0.19342857142857142, 0.06483121857792673)\n",
            "epoch  2 loss  0.012555471475635255 Train Accuracy & F1 (0.20467857142857143, 0.09025884884966104) Validation Accuracy & F1  (0.19314285714285714, 0.10783242258652095)\n",
            "epoch  3 loss  0.012544611866985049 Train Accuracy & F1 (0.21335714285714286, 0.13146860274417146) Validation Accuracy & F1  (0.19542857142857142, 0.11520393366782374)\n",
            "epoch  4 loss  0.012526510055576052 Train Accuracy & F1 (0.23157142857142857, 0.18743280143634486) Validation Accuracy & F1  (0.20857142857142857, 0.13924264999004152)\n",
            "epoch  5 loss  0.012489991647856576 Train Accuracy & F1 (0.24567857142857144, 0.20819340094862748) Validation Accuracy & F1  (0.21257142857142858, 0.1514178645810465)\n",
            "epoch  6 loss  0.012385521922792707 Train Accuracy & F1 (0.26989285714285716, 0.22903943354752904) Validation Accuracy & F1  (0.22885714285714287, 0.15635948640750857)\n",
            "epoch  7 loss  0.011954585079635892 Train Accuracy & F1 (0.30292857142857144, 0.27131562099682616) Validation Accuracy & F1  (0.23685714285714285, 0.17747675312961353)\n",
            "epoch  8 loss  0.011397400851760591 Train Accuracy & F1 (0.25160714285714286, 0.1773609300066911) Validation Accuracy & F1  (0.21142857142857144, 0.10652292410455208)\n",
            "epoch  9 loss  0.011055419679198946 Train Accuracy & F1 (0.37039285714285713, 0.3293936807665873) Validation Accuracy & F1  (0.31685714285714284, 0.25225237509049253)\n",
            "epoch  10 loss  0.010758175560406277 Train Accuracy & F1 (0.20067857142857143, 0.06685505220262351) Validation Accuracy & F1  (0.19514285714285715, 0.06531197704996414)\n",
            "{'layers': 3, 'hidden_size': 400}\n",
            "epoch  1 loss  0.012545390435627529 Train Accuracy & F1 (0.20089285714285715, 0.06802547755700346) Validation Accuracy & F1  (0.19257142857142856, 0.06459032103497844)\n",
            "epoch  2 loss  0.012557317980698177 Train Accuracy & F1 (0.20482142857142857, 0.09292968546899856) Validation Accuracy & F1  (0.19285714285714287, 0.11088298918387414)\n",
            "epoch  3 loss  0.012548374916825976 Train Accuracy & F1 (0.21392857142857144, 0.13661840256152086) Validation Accuracy & F1  (0.1982857142857143, 0.11852010635567793)\n",
            "epoch  4 loss  0.012533368923834392 Train Accuracy & F1 (0.22435714285714287, 0.1630838184709294) Validation Accuracy & F1  (0.20514285714285715, 0.13368544329383544)\n",
            "epoch  5 loss  0.01250413520847048 Train Accuracy & F1 (0.22807142857142856, 0.16634122669060067) Validation Accuracy & F1  (0.20942857142857144, 0.13803349501271492)\n",
            "epoch  6 loss  0.012428940517561776 Train Accuracy & F1 (0.26539285714285715, 0.2275005071188021) Validation Accuracy & F1  (0.21942857142857142, 0.1487339571458254)\n",
            "epoch  7 loss  0.012200640218598503 Train Accuracy & F1 (0.2651428571428571, 0.2053487360379922) Validation Accuracy & F1  (0.21742857142857142, 0.12281422302004788)\n",
            "epoch  8 loss  0.011686736260141646 Train Accuracy & F1 (0.2951785714285714, 0.256297054404752) Validation Accuracy & F1  (0.22457142857142856, 0.14477070007148274)\n",
            "epoch  9 loss  0.01128223751272474 Train Accuracy & F1 (0.33732142857142855, 0.3140324522274312) Validation Accuracy & F1  (0.28914285714285715, 0.23694691787103186)\n",
            "epoch  10 loss  0.010963207879236766 Train Accuracy & F1 (0.3391071428571429, 0.3165346319235817) Validation Accuracy & F1  (0.2862857142857143, 0.25082650237045073)\n",
            "{'layers': 3, 'hidden_size': 500}\n",
            "epoch  1 loss  0.012542786121368409 Train Accuracy & F1 (0.20110714285714285, 0.06846774242053154) Validation Accuracy & F1  (0.19314285714285714, 0.06475095785440613)\n",
            "epoch  2 loss  0.012555200151034764 Train Accuracy & F1 (0.20607142857142857, 0.0990880926020081) Validation Accuracy & F1  (0.19428571428571428, 0.11153495124612114)\n",
            "epoch  3 loss  0.012543423448290144 Train Accuracy & F1 (0.21542857142857144, 0.13858005253084413) Validation Accuracy & F1  (0.20057142857142857, 0.11503067532640601)\n",
            "epoch  4 loss  0.012522070778267724 Train Accuracy & F1 (0.22892857142857143, 0.1676843776236048) Validation Accuracy & F1  (0.20657142857142857, 0.1327326805186207)\n",
            "epoch  5 loss  0.012475240443434035 Train Accuracy & F1 (0.24296428571428572, 0.192965878463381) Validation Accuracy & F1  (0.20914285714285713, 0.13715686171295208)\n",
            "epoch  6 loss  0.012362556959901537 Train Accuracy & F1 (0.2730714285714286, 0.2380785370711914) Validation Accuracy & F1  (0.22428571428571428, 0.15255080389421888)\n",
            "epoch  7 loss  0.012023872452122825 Train Accuracy & F1 (0.29414285714285715, 0.253669811486336) Validation Accuracy & F1  (0.23257142857142857, 0.16469953162999168)\n",
            "epoch  8 loss  0.011486747005156108 Train Accuracy & F1 (0.32275, 0.26390099256995386) Validation Accuracy & F1  (0.2822857142857143, 0.20912712200669653)\n",
            "epoch  9 loss  0.011101080860410418 Train Accuracy & F1 (0.35317857142857145, 0.34534151756004394) Validation Accuracy & F1  (0.32885714285714285, 0.2995665415130708)\n",
            "epoch  10 loss  0.010769287492547717 Train Accuracy & F1 (0.22335714285714287, 0.11728611472507995) Validation Accuracy & F1  (0.20857142857142857, 0.09433466473727323)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0.20057142857142857, 1, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.206, 2, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.21, 3, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.23285714285714285, 4, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.27485714285714286, 5, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.3417142857142857, 6, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.388, 7, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.388, 7, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.3945714285714286, 9, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.3945714285714286, 9, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.20142857142857143, 1, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.2057142857142857, 2, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.21457142857142858, 3, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.23285714285714285, 4, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.32371428571428573, 5, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.35428571428571426, 6, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.37114285714285716, 7, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.37114285714285716, 7, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.37114285714285716, 7, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.42542857142857143, 10, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19942857142857143, 1, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.20057142857142857, 2, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.2082857142857143, 3, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.22685714285714287, 4, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.31942857142857145, 5, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.3648571428571429, 6, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.3648571428571429, 6, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.3648571428571429, 6, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.39885714285714285, 9, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.4431428571428571, 10, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.2017142857142857, 1, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.2042857142857143, 2, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.21142857142857144, 3, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.2622857142857143, 4, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.2622857142857143, 4, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.34514285714285714, 6, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.35514285714285715, 7, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.39085714285714285, 8, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.4045714285714286, 9, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.4045714285714286, 9, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.2002857142857143, 1, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.20314285714285715, 2, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.21, 3, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.27685714285714286, 4, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.2782857142857143, 5, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.2822857142857143, 6, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.2822857142857143, 6, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.3717142857142857, 8, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.3717142857142857, 8, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.4328571428571429, 10, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.206, 1, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.21085714285714285, 2, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.21085714285714285, 2, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.21828571428571428, 4, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.23885714285714285, 5, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.31657142857142856, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.31657142857142856, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.31657142857142856, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.348, 9, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.348, 9, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.2022857142857143, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.208, 2, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.21085714285714285, 3, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.22171428571428572, 4, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.23742857142857143, 5, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.23742857142857143, 5, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.2977142857142857, 7, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.37057142857142855, 8, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.4005714285714286, 9, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.4005714285714286, 9, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.20485714285714285, 1, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.206, 2, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.214, 3, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.22542857142857142, 4, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.2742857142857143, 5, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.2742857142857143, 5, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.2742857142857143, 5, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.308, 8, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.308, 8, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.31314285714285717, 10, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.19942857142857143, 1, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.2057142857142857, 2, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.208, 3, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.23314285714285715, 4, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.27171428571428574, 5, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.27171428571428574, 5, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.3357142857142857, 7, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.3357142857142857, 7, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.3417142857142857, 9, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.3417142857142857, 9, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.2002857142857143, 1, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.20914285714285713, 2, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.21685714285714286, 3, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.238, 4, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.31885714285714284, 5, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.33285714285714285, 6, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.3362857142857143, 7, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.35628571428571426, 8, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.35628571428571426, 8, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.35628571428571426, 8, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.19485714285714287, 5, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.19657142857142856, 6, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.20514285714285715, 7, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.20542857142857143, 8, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.21828571428571428, 9, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.23085714285714284, 10, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.19714285714285715, 4, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.21057142857142858, 5, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.2337142857142857, 6, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.2745714285714286, 7, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.2745714285714286, 7, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.3485714285714286, 9, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.3485714285714286, 9, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.19542857142857142, 3, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.20857142857142857, 4, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.21257142857142858, 5, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.22885714285714287, 6, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.23685714285714285, 7, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.23685714285714285, 7, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.31685714285714284, 9, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.31685714285714284, 9, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.19257142857142856, 1, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.19285714285714287, 2, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.1982857142857143, 3, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.20514285714285715, 4, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.20942857142857144, 5, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.21942857142857142, 6, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.21942857142857142, 6, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.22457142857142856, 8, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.28914285714285715, 9, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.28914285714285715, 9, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.19314285714285714, 1, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.19428571428571428, 2, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.20057142857142857, 3, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.20657142857142857, 4, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.20914285714285713, 5, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.22428571428571428, 6, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.23257142857142857, 7, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.2822857142857143, 8, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.32885714285714285, 9, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.32885714285714285, 9, {'hidden_size': 500, 'layers': 3})]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling the hyperparamater optimization for LSTM\n",
        "layers_list = [1, 2, 3]\n",
        "hidden_size_list = [100, 200, 300, 400, 500]\n",
        "random_search(hidden_size_list,layers_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOFtpcvustx2",
        "outputId": "5b81e01e-3c43-43a0-9cf8-98ff5b3d4bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'layers': 1, 'hidden_size': 100}\n",
            "epoch  1 loss  0.012467223639999117 Train Accuracy & F1 (0.24025, 0.2009991723701005) Validation Accuracy & F1  (0.20457142857142857, 0.09401845629764669)\n",
            "epoch  2 loss  0.012156574325902121 Train Accuracy & F1 (0.29267857142857145, 0.27796937765618857) Validation Accuracy & F1  (0.22457142857142856, 0.14935808339511786)\n",
            "epoch  3 loss  0.01180074484007699 Train Accuracy & F1 (0.33153571428571427, 0.32245941371911524) Validation Accuracy & F1  (0.2782857142857143, 0.23607915813859828)\n",
            "epoch  4 loss  0.01137922260590962 Train Accuracy & F1 (0.3699642857142857, 0.36316473653574527) Validation Accuracy & F1  (0.32285714285714284, 0.2928692996212117)\n",
            "epoch  5 loss  0.010735602063792092 Train Accuracy & F1 (0.427, 0.4101477712656755) Validation Accuracy & F1  (0.37714285714285717, 0.3299930264341712)\n",
            "epoch  6 loss  0.010071007668972015 Train Accuracy & F1 (0.46267857142857144, 0.4481340561097754) Validation Accuracy & F1  (0.39285714285714285, 0.35179187174711085)\n",
            "epoch  7 loss  0.009467406055756978 Train Accuracy & F1 (0.48792857142857143, 0.47964305827251846) Validation Accuracy & F1  (0.422, 0.4099180426422248)\n",
            "epoch  8 loss  0.008985323173659188 Train Accuracy & F1 (0.5151071428571429, 0.5020216324099597) Validation Accuracy & F1  (0.42457142857142854, 0.38947532467484247)\n",
            "epoch  9 loss  0.00860609801539353 Train Accuracy & F1 (0.53075, 0.5137799193777006) Validation Accuracy & F1  (0.44285714285714284, 0.4066062350611695)\n",
            "epoch  10 loss  0.008233340510300228 Train Accuracy & F1 (0.5065357142857143, 0.506696009461469) Validation Accuracy & F1  (0.4188571428571429, 0.41170861009556337)\n",
            "{'layers': 1, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012420601542506899 Train Accuracy & F1 (0.2387142857142857, 0.19264482974671124) Validation Accuracy & F1  (0.2, 0.08368151761139928)\n",
            "epoch  2 loss  0.012089092714445932 Train Accuracy & F1 (0.26667857142857143, 0.22916507550951798) Validation Accuracy & F1  (0.20114285714285715, 0.08737997929864205)\n",
            "epoch  3 loss  0.011669160936559949 Train Accuracy & F1 (0.3268214285714286, 0.30110057969817783) Validation Accuracy & F1  (0.23485714285714285, 0.14682816169187307)\n",
            "epoch  4 loss  0.010986519911459514 Train Accuracy & F1 (0.319, 0.2801734100983608) Validation Accuracy & F1  (0.236, 0.15296523625789435)\n",
            "epoch  5 loss  0.010337438259805952 Train Accuracy & F1 (0.42939285714285713, 0.38426072098688147) Validation Accuracy & F1  (0.36228571428571427, 0.2673686756077836)\n",
            "epoch  6 loss  0.00974506892476763 Train Accuracy & F1 (0.4835, 0.4645841366175967) Validation Accuracy & F1  (0.4154285714285714, 0.3800524089510895)\n",
            "epoch  7 loss  0.009315941386989185 Train Accuracy & F1 (0.49607142857142855, 0.4728754333626708) Validation Accuracy & F1  (0.39685714285714285, 0.32392537995404175)\n",
            "epoch  8 loss  0.008795459059732301 Train Accuracy & F1 (0.46789285714285717, 0.45756761455574) Validation Accuracy & F1  (0.3757142857142857, 0.35361691853003263)\n",
            "epoch  9 loss  0.008278604164719582 Train Accuracy & F1 (0.5513928571428571, 0.5409568858091806) Validation Accuracy & F1  (0.45285714285714285, 0.4248870163149803)\n",
            "epoch  10 loss  0.007934184653418405 Train Accuracy & F1 (0.5556071428571429, 0.5351517466763932) Validation Accuracy & F1  (0.45371428571428574, 0.4032877042129642)\n",
            "{'layers': 1, 'hidden_size': 300}\n",
            "epoch  1 loss  0.01248122820683888 Train Accuracy & F1 (0.23817857142857143, 0.19045611880578034) Validation Accuracy & F1  (0.1997142857142857, 0.08481687911860986)\n",
            "epoch  2 loss  0.012152903084244047 Train Accuracy & F1 (0.27482142857142855, 0.23824965922291028) Validation Accuracy & F1  (0.20514285714285715, 0.0957601322917639)\n",
            "epoch  3 loss  0.011623482184750693 Train Accuracy & F1 (0.3394642857142857, 0.30175872803068426) Validation Accuracy & F1  (0.2557142857142857, 0.16524943290237393)\n",
            "epoch  4 loss  0.010884597327028001 Train Accuracy & F1 (0.40667857142857144, 0.3640902884063406) Validation Accuracy & F1  (0.3314285714285714, 0.23692741545093807)\n",
            "epoch  5 loss  0.010306116257395062 Train Accuracy & F1 (0.42642857142857143, 0.3909957201741181) Validation Accuracy & F1  (0.3628571428571429, 0.3006160898137382)\n",
            "epoch  6 loss  0.009794947479452405 Train Accuracy & F1 (0.4564285714285714, 0.4122903207883956) Validation Accuracy & F1  (0.402, 0.3372164743630136)\n",
            "epoch  7 loss  0.009455682020102229 Train Accuracy & F1 (0.3903214285714286, 0.34815272466423924) Validation Accuracy & F1  (0.3357142857142857, 0.2690790171665679)\n",
            "epoch  8 loss  0.00897937609255314 Train Accuracy & F1 (0.5068928571428571, 0.4912913544489152) Validation Accuracy & F1  (0.44771428571428573, 0.42778482212754215)\n",
            "epoch  9 loss  0.008548973068594933 Train Accuracy & F1 (0.5458571428571428, 0.5164504206258351) Validation Accuracy & F1  (0.4697142857142857, 0.41262921774796146)\n",
            "epoch  10 loss  0.008152446148650986 Train Accuracy & F1 (0.5786785714285714, 0.5671998125447707) Validation Accuracy & F1  (0.4734285714285714, 0.427379353854923)\n",
            "{'layers': 1, 'hidden_size': 400}\n",
            "epoch  1 loss  0.012504902460745402 Train Accuracy & F1 (0.23957142857142857, 0.19294793876061694) Validation Accuracy & F1  (0.202, 0.0871723144341732)\n",
            "epoch  2 loss  0.012158205330371857 Train Accuracy & F1 (0.27525, 0.23882084459968506) Validation Accuracy & F1  (0.21085714285714285, 0.1048779937918441)\n",
            "epoch  3 loss  0.011644131460360118 Train Accuracy & F1 (0.3642142857142857, 0.325966911602445) Validation Accuracy & F1  (0.29828571428571427, 0.21210869360391613)\n",
            "epoch  4 loss  0.010866517688546863 Train Accuracy & F1 (0.30935714285714283, 0.26392132271920027) Validation Accuracy & F1  (0.24457142857142858, 0.15450717807026176)\n",
            "epoch  5 loss  0.010490772132362639 Train Accuracy & F1 (0.4180357142857143, 0.3620774078748634) Validation Accuracy & F1  (0.344, 0.2469425592481181)\n",
            "epoch  6 loss  0.010019498007638114 Train Accuracy & F1 (0.45271428571428574, 0.4308970732042511) Validation Accuracy & F1  (0.37, 0.31009252153867534)\n",
            "epoch  7 loss  0.009632226543767112 Train Accuracy & F1 (0.44789285714285715, 0.39453496812257394) Validation Accuracy & F1  (0.3871428571428571, 0.30363962257546595)\n",
            "epoch  8 loss  0.009215822077223233 Train Accuracy & F1 (0.48560714285714285, 0.4425643679076141) Validation Accuracy & F1  (0.428, 0.3634923363941459)\n",
            "epoch  9 loss  0.008814962983131409 Train Accuracy & F1 (0.5323571428571429, 0.5071643464031178) Validation Accuracy & F1  (0.44771428571428573, 0.3804363350377054)\n",
            "epoch  10 loss  0.008462977794664246 Train Accuracy & F1 (0.5673214285714285, 0.5583312915709892) Validation Accuracy & F1  (0.47114285714285714, 0.45680395841670557)\n",
            "{'layers': 1, 'hidden_size': 500}\n",
            "epoch  1 loss  0.012497363473687854 Train Accuracy & F1 (0.2365357142857143, 0.1880911619280868) Validation Accuracy & F1  (0.198, 0.0816551406004339)\n",
            "epoch  2 loss  0.012188332557678223 Train Accuracy & F1 (0.27860714285714283, 0.2425548747252711) Validation Accuracy & F1  (0.20914285714285713, 0.10218325995519395)\n",
            "epoch  3 loss  0.011693154590470451 Train Accuracy & F1 (0.36078571428571427, 0.34859327940875096) Validation Accuracy & F1  (0.282, 0.23660352473205384)\n",
            "epoch  4 loss  0.011031004829066141 Train Accuracy & F1 (0.38875, 0.3680768126562014) Validation Accuracy & F1  (0.31142857142857144, 0.22951339135457602)\n",
            "epoch  5 loss  0.01054875476019723 Train Accuracy & F1 (0.4057142857142857, 0.35325278248504444) Validation Accuracy & F1  (0.36628571428571427, 0.28689836006876196)\n",
            "epoch  6 loss  0.01021676817536354 Train Accuracy & F1 (0.4482857142857143, 0.4214084219815112) Validation Accuracy & F1  (0.394, 0.3450486011034698)\n",
            "epoch  7 loss  0.009908191791602544 Train Accuracy & F1 (0.4069285714285714, 0.3868876403208673) Validation Accuracy & F1  (0.3442857142857143, 0.2956974850096057)\n",
            "epoch  8 loss  0.009461949918951306 Train Accuracy & F1 (0.3480357142857143, 0.30916236566772654) Validation Accuracy & F1  (0.28, 0.21263683692761148)\n",
            "epoch  9 loss  0.009271097513181822 Train Accuracy & F1 (0.38785714285714284, 0.3458661586959771) Validation Accuracy & F1  (0.3482857142857143, 0.2907683167458206)\n",
            "epoch  10 loss  0.00885171491759164 Train Accuracy & F1 (0.5321071428571429, 0.5034352462875736) Validation Accuracy & F1  (0.4451428571428571, 0.3935146943640474)\n",
            "{'layers': 2, 'hidden_size': 100}\n",
            "epoch  1 loss  0.012424382324729647 Train Accuracy & F1 (0.25842857142857145, 0.21761857915013647) Validation Accuracy & F1  (0.206, 0.10014125436957229)\n",
            "epoch  2 loss  0.011999349687780653 Train Accuracy & F1 (0.31885714285714284, 0.30179793779783964) Validation Accuracy & F1  (0.23142857142857143, 0.15235237101233792)\n",
            "epoch  3 loss  0.011249677236591066 Train Accuracy & F1 (0.3567142857142857, 0.3389758650339228) Validation Accuracy & F1  (0.24085714285714285, 0.16477044504547514)\n",
            "epoch  4 loss  0.010527246815817697 Train Accuracy & F1 (0.42042857142857143, 0.3707908702631377) Validation Accuracy & F1  (0.3437142857142857, 0.24351538823361868)\n",
            "epoch  5 loss  0.0100803442129067 Train Accuracy & F1 (0.22342857142857142, 0.11788461805252663) Validation Accuracy & F1  (0.2077142857142857, 0.09249123990174721)\n",
            "epoch  6 loss  0.009896040737628937 Train Accuracy & F1 (0.45935714285714285, 0.42302589227005677) Validation Accuracy & F1  (0.4, 0.34728635289317633)\n",
            "epoch  7 loss  0.009225049208317484 Train Accuracy & F1 (0.5060714285714286, 0.47933992519082375) Validation Accuracy & F1  (0.44057142857142856, 0.4116178077962874)\n",
            "epoch  8 loss  0.008871804113898958 Train Accuracy & F1 (0.5273214285714286, 0.5109205415349332) Validation Accuracy & F1  (0.45457142857142857, 0.42566761960862837)\n",
            "epoch  9 loss  0.00842572506410735 Train Accuracy & F1 (0.3198214285714286, 0.25291940026671383) Validation Accuracy & F1  (0.27285714285714285, 0.18984777822429338)\n",
            "epoch  10 loss  0.008109089681080409 Train Accuracy & F1 (0.57875, 0.5708274870855672) Validation Accuracy & F1  (0.49314285714285716, 0.4816315855854484)\n",
            "{'layers': 2, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012398906001022884 Train Accuracy & F1 (0.24367857142857144, 0.19288555115807354) Validation Accuracy & F1  (0.2022857142857143, 0.0878457498385091)\n",
            "epoch  2 loss  0.011962550231388636 Train Accuracy & F1 (0.2973928571428571, 0.26562982584058004) Validation Accuracy & F1  (0.21942857142857142, 0.12127321115377228)\n",
            "epoch  3 loss  0.01125439731989588 Train Accuracy & F1 (0.39617857142857144, 0.3647499380958594) Validation Accuracy & F1  (0.3028571428571429, 0.23195801526197973)\n",
            "epoch  4 loss  0.010683595678636006 Train Accuracy & F1 (0.3485357142857143, 0.30554207949262624) Validation Accuracy & F1  (0.27085714285714285, 0.19158886272669423)\n",
            "epoch  5 loss  0.010201622256210872 Train Accuracy & F1 (0.38039285714285714, 0.34615705532503743) Validation Accuracy & F1  (0.28085714285714286, 0.23335424120952686)\n",
            "epoch  6 loss  0.009813430096421922 Train Accuracy & F1 (0.48442857142857143, 0.462219951242839) Validation Accuracy & F1  (0.4288571428571429, 0.4218498744883238)\n",
            "epoch  7 loss  0.00945056703048093 Train Accuracy & F1 (0.49139285714285713, 0.45551019184957253) Validation Accuracy & F1  (0.4102857142857143, 0.36005050396688293)\n",
            "epoch  8 loss  0.009117824562958309 Train Accuracy & F1 (0.49107142857142855, 0.48430411840467746) Validation Accuracy & F1  (0.41628571428571426, 0.3837174149531214)\n",
            "epoch  9 loss  0.00888492583164147 Train Accuracy & F1 (0.5248214285714285, 0.49234381218190615) Validation Accuracy & F1  (0.45485714285714285, 0.41533306116260044)\n",
            "epoch  10 loss  0.00853859495478017 Train Accuracy & F1 (0.5044642857142857, 0.489148927821249) Validation Accuracy & F1  (0.43114285714285716, 0.3933355471444883)\n",
            "{'layers': 2, 'hidden_size': 300}\n",
            "epoch  1 loss  0.01238647249341011 Train Accuracy & F1 (0.26203571428571426, 0.2217431155022267) Validation Accuracy & F1  (0.20514285714285715, 0.09722198051605678)\n",
            "epoch  2 loss  0.01196158145580973 Train Accuracy & F1 (0.30196428571428574, 0.26735352818425595) Validation Accuracy & F1  (0.21142857142857144, 0.10701659640782044)\n",
            "epoch  3 loss  0.01136943805217743 Train Accuracy & F1 (0.29925, 0.23401462104984133) Validation Accuracy & F1  (0.21971428571428572, 0.11481709327112447)\n",
            "epoch  4 loss  0.010897076155458178 Train Accuracy & F1 (0.39475, 0.3355700537115594) Validation Accuracy & F1  (0.30657142857142855, 0.238514485675161)\n",
            "epoch  5 loss  0.010307391213519233 Train Accuracy & F1 (0.4451785714285714, 0.40415904155651283) Validation Accuracy & F1  (0.3545714285714286, 0.29079448254918167)\n",
            "epoch  6 loss  0.009917949510472162 Train Accuracy & F1 (0.45714285714285713, 0.4268640302026423) Validation Accuracy & F1  (0.354, 0.29735902177116075)\n",
            "epoch  7 loss  0.009718418681195804 Train Accuracy & F1 (0.30225, 0.24888861170482937) Validation Accuracy & F1  (0.2634285714285714, 0.2045947743019021)\n",
            "epoch  8 loss  0.009305297378982816 Train Accuracy & F1 (0.42596428571428574, 0.4144171384340746) Validation Accuracy & F1  (0.38285714285714284, 0.3443694733404071)\n",
            "epoch  9 loss  0.00898977301801954 Train Accuracy & F1 (0.51725, 0.4822911690269745) Validation Accuracy & F1  (0.4377142857142857, 0.37535869639642205)\n",
            "epoch  10 loss  0.008632573830229896 Train Accuracy & F1 (0.5268928571428572, 0.5038530038860511) Validation Accuracy & F1  (0.4237142857142857, 0.3580372856458848)\n",
            "{'layers': 2, 'hidden_size': 400}\n",
            "epoch  1 loss  0.012390863026891435 Train Accuracy & F1 (0.2613214285714286, 0.2230535881979705) Validation Accuracy & F1  (0.2062857142857143, 0.09929816926417002)\n",
            "epoch  2 loss  0.011902571094887597 Train Accuracy & F1 (0.308, 0.2838466062229741) Validation Accuracy & F1  (0.21485714285714286, 0.11534319474471752)\n",
            "epoch  3 loss  0.011329427084752491 Train Accuracy & F1 (0.3781785714285714, 0.3391234544179339) Validation Accuracy & F1  (0.2662857142857143, 0.1915821311436022)\n",
            "epoch  4 loss  0.010884145719664437 Train Accuracy & F1 (0.41135714285714287, 0.38710483203980034) Validation Accuracy & F1  (0.2785714285714286, 0.21013595513046135)\n",
            "epoch  5 loss  0.010455521000283106 Train Accuracy & F1 (0.4323214285714286, 0.3965879990894644) Validation Accuracy & F1  (0.324, 0.2571988973792653)\n",
            "epoch  6 loss  0.010152812153100967 Train Accuracy & F1 (0.3627142857142857, 0.28906738553085465) Validation Accuracy & F1  (0.2948571428571429, 0.20743768782131955)\n",
            "epoch  7 loss  0.00990202180828367 Train Accuracy & F1 (0.3925, 0.30733634818322) Validation Accuracy & F1  (0.29828571428571427, 0.21845038550241477)\n",
            "epoch  8 loss  0.009559569563184466 Train Accuracy & F1 (0.49689285714285714, 0.46734722368253967) Validation Accuracy & F1  (0.386, 0.3273051924656051)\n",
            "epoch  9 loss  0.00930211615562439 Train Accuracy & F1 (0.38321428571428573, 0.35217792953442173) Validation Accuracy & F1  (0.31085714285714283, 0.24665088716772204)\n",
            "epoch  10 loss  0.00955327267731939 Train Accuracy & F1 (0.45289285714285715, 0.45066130893841316) Validation Accuracy & F1  (0.36457142857142855, 0.3404895595792683)\n",
            "{'layers': 2, 'hidden_size': 500}\n",
            "epoch  1 loss  0.012403552149023328 Train Accuracy & F1 (0.25275, 0.19670391679672306) Validation Accuracy & F1  (0.20142857142857143, 0.08583863132504096)\n",
            "epoch  2 loss  0.01200824049115181 Train Accuracy & F1 (0.3177142857142857, 0.2974733115751696) Validation Accuracy & F1  (0.2322857142857143, 0.1501003352455607)\n",
            "epoch  3 loss  0.011412832711424147 Train Accuracy & F1 (0.35578571428571426, 0.3140816052437267) Validation Accuracy & F1  (0.2737142857142857, 0.20914681991608558)\n",
            "epoch  4 loss  0.010951493544237955 Train Accuracy & F1 (0.32160714285714287, 0.282134408240087) Validation Accuracy & F1  (0.21571428571428572, 0.12218061561337237)\n",
            "epoch  5 loss  0.01058929933820452 Train Accuracy & F1 (0.3812857142857143, 0.3518144500494048) Validation Accuracy & F1  (0.26, 0.1822159505039918)\n",
            "epoch  6 loss  0.010248987776892525 Train Accuracy & F1 (0.4085, 0.33543467022651813) Validation Accuracy & F1  (0.33171428571428574, 0.25018472504544353)\n",
            "epoch  7 loss  0.009929045076881136 Train Accuracy & F1 (0.40025, 0.33033797091973927) Validation Accuracy & F1  (0.31142857142857144, 0.22625431248601907)\n",
            "epoch  8 loss  0.009569059755120958 Train Accuracy & F1 (0.4625357142857143, 0.41001425337569175) Validation Accuracy & F1  (0.37314285714285716, 0.2888830550069895)\n",
            "epoch  9 loss  0.00937369393663747 Train Accuracy & F1 (0.35942857142857143, 0.31733435503121865) Validation Accuracy & F1  (0.25457142857142856, 0.17908461475452112)\n",
            "epoch  10 loss  0.00911818953709943 Train Accuracy & F1 (0.47860714285714284, 0.418036503942918) Validation Accuracy & F1  (0.40285714285714286, 0.3079845658565567)\n",
            "{'layers': 3, 'hidden_size': 100}\n",
            "epoch  1 loss  0.012458050293581826 Train Accuracy & F1 (0.26439285714285715, 0.23884783040152877) Validation Accuracy & F1  (0.21171428571428572, 0.12089346261835518)\n",
            "epoch  2 loss  0.011944312019007546 Train Accuracy & F1 (0.32539285714285715, 0.3106165915524794) Validation Accuracy & F1  (0.24371428571428572, 0.1839615684725435)\n",
            "epoch  3 loss  0.011209645594869342 Train Accuracy & F1 (0.3795, 0.358403241501668) Validation Accuracy & F1  (0.29514285714285715, 0.24120707327680577)\n",
            "epoch  4 loss  0.010628615881715502 Train Accuracy & F1 (0.42657142857142855, 0.38818029382722335) Validation Accuracy & F1  (0.348, 0.2764366795443291)\n",
            "epoch  5 loss  0.010144123290266309 Train Accuracy & F1 (0.42857142857142855, 0.4023282369726597) Validation Accuracy & F1  (0.31657142857142856, 0.281531205605082)\n",
            "epoch  6 loss  0.00969866863318852 Train Accuracy & F1 (0.3533928571428571, 0.30961148474134303) Validation Accuracy & F1  (0.29514285714285715, 0.2399993565584136)\n",
            "epoch  7 loss  0.009312113913042205 Train Accuracy & F1 (0.47332142857142856, 0.4337399883185479) Validation Accuracy & F1  (0.4197142857142857, 0.37621194533162605)\n",
            "epoch  8 loss  0.008978769151227814 Train Accuracy & F1 (0.5144642857142857, 0.49710672157576985) Validation Accuracy & F1  (0.44257142857142856, 0.42374611237003484)\n",
            "epoch  9 loss  0.00895509369458471 Train Accuracy & F1 (0.45225, 0.42821698196564917) Validation Accuracy & F1  (0.36114285714285715, 0.33045674860694485)\n",
            "epoch  10 loss  0.008507698056953294 Train Accuracy & F1 (0.5310357142857143, 0.5109150920737588) Validation Accuracy & F1  (0.4462857142857143, 0.4142444057618298)\n",
            "{'layers': 3, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012387753260987145 Train Accuracy & F1 (0.2756071428571429, 0.23211096555322666) Validation Accuracy & F1  (0.21228571428571427, 0.11525805322562292)\n",
            "epoch  2 loss  0.011802124606711524 Train Accuracy & F1 (0.32303571428571426, 0.29088449560671303) Validation Accuracy & F1  (0.22428571428571428, 0.13156294516885286)\n",
            "epoch  3 loss  0.011169580123254232 Train Accuracy & F1 (0.3752142857142857, 0.3464434033093512) Validation Accuracy & F1  (0.2631428571428571, 0.19282246640338926)\n",
            "epoch  4 loss  0.010648293371711458 Train Accuracy & F1 (0.432, 0.39218006842415887) Validation Accuracy & F1  (0.3565714285714286, 0.29778273097888375)\n",
            "epoch  5 loss  0.010273574241570063 Train Accuracy & F1 (0.4433214285714286, 0.39254369084065177) Validation Accuracy & F1  (0.37085714285714283, 0.2871944012369743)\n",
            "epoch  6 loss  0.009914087248700005 Train Accuracy & F1 (0.44285714285714284, 0.42527724155150876) Validation Accuracy & F1  (0.39371428571428574, 0.3679292211414353)\n",
            "epoch  7 loss  0.009580758303403854 Train Accuracy & F1 (0.32360714285714287, 0.1937956711170109) Validation Accuracy & F1  (0.2402857142857143, 0.13604511522493018)\n",
            "epoch  8 loss  0.009571137328233038 Train Accuracy & F1 (0.37007142857142855, 0.3177794521492513) Validation Accuracy & F1  (0.3057142857142857, 0.23006740187302333)\n",
            "epoch  9 loss  0.009092043793627195 Train Accuracy & F1 (0.4763928571428571, 0.47643251811982645) Validation Accuracy & F1  (0.3454285714285714, 0.32729802944990505)\n",
            "epoch  10 loss  0.009031168396983829 Train Accuracy & F1 (0.5202142857142857, 0.4786754638645295) Validation Accuracy & F1  (0.426, 0.3646973267119436)\n",
            "{'layers': 3, 'hidden_size': 300}\n",
            "epoch  1 loss  0.012383689024618694 Train Accuracy & F1 (0.27053571428571427, 0.22221650587998337) Validation Accuracy & F1  (0.21371428571428572, 0.11365102073878379)\n",
            "epoch  2 loss  0.011779002168348858 Train Accuracy & F1 (0.335, 0.32369388594569876) Validation Accuracy & F1  (0.2542857142857143, 0.21450982157658527)\n",
            "epoch  3 loss  0.011204260340758733 Train Accuracy & F1 (0.36257142857142854, 0.31092478920752625) Validation Accuracy & F1  (0.258, 0.18029168114578503)\n",
            "epoch  4 loss  0.010832423516682217 Train Accuracy & F1 (0.36225, 0.31321244324649944) Validation Accuracy & F1  (0.27171428571428574, 0.19757443459255786)\n",
            "epoch  5 loss  0.010431520112923214 Train Accuracy & F1 (0.3658571428571429, 0.305512061675901) Validation Accuracy & F1  (0.24114285714285713, 0.15400523664854157)\n",
            "epoch  6 loss  0.01012635965006692 Train Accuracy & F1 (0.43039285714285713, 0.3815012243366311) Validation Accuracy & F1  (0.3522857142857143, 0.2866904553459388)\n",
            "epoch  7 loss  0.009743348096098219 Train Accuracy & F1 (0.3520357142857143, 0.30368180576974235) Validation Accuracy & F1  (0.28, 0.22505740547393133)\n",
            "epoch  8 loss  0.009494827172585896 Train Accuracy & F1 (0.48614285714285715, 0.452724732955131) Validation Accuracy & F1  (0.38542857142857145, 0.3108177633484603)\n",
            "epoch  9 loss  0.009262718204941069 Train Accuracy & F1 (0.44435714285714284, 0.4252387311832659) Validation Accuracy & F1  (0.358, 0.3312373027481143)\n",
            "epoch  10 loss  0.008963431126305035 Train Accuracy & F1 (0.4441428571428571, 0.4045185416342215) Validation Accuracy & F1  (0.29914285714285715, 0.23320513123796296)\n",
            "{'layers': 3, 'hidden_size': 400}\n",
            "epoch  1 loss  0.012382256184305463 Train Accuracy & F1 (0.2794642857142857, 0.24114869139094858) Validation Accuracy & F1  (0.212, 0.11437457427535688)\n",
            "epoch  2 loss  0.01181867316365242 Train Accuracy & F1 (0.30192857142857144, 0.23649143739361184) Validation Accuracy & F1  (0.22314285714285714, 0.12264836804315489)\n",
            "epoch  3 loss  0.011323477366140911 Train Accuracy & F1 (0.3404285714285714, 0.28536347058388517) Validation Accuracy & F1  (0.23857142857142857, 0.15041382745833315)\n",
            "epoch  4 loss  0.01096208216888564 Train Accuracy & F1 (0.3966071428571429, 0.3441752171263106) Validation Accuracy & F1  (0.28685714285714287, 0.21802474986158402)\n",
            "epoch  5 loss  0.010587359824350903 Train Accuracy & F1 (0.3522142857142857, 0.31801537871291535) Validation Accuracy & F1  (0.27714285714285714, 0.22786517635501596)\n",
            "epoch  6 loss  0.010241527097565787 Train Accuracy & F1 (0.42064285714285715, 0.35872720748425735) Validation Accuracy & F1  (0.3231428571428571, 0.25388793966363876)\n",
            "epoch  7 loss  0.00988842196549688 Train Accuracy & F1 (0.44671428571428573, 0.4244824298577699) Validation Accuracy & F1  (0.3474285714285714, 0.27079419313702047)\n",
            "epoch  8 loss  0.009742499570761409 Train Accuracy & F1 (0.23832142857142857, 0.14227884683173794) Validation Accuracy & F1  (0.21314285714285713, 0.10352466852867667)\n",
            "epoch  9 loss  0.009501857751182147 Train Accuracy & F1 (0.28614285714285714, 0.24927616970973596) Validation Accuracy & F1  (0.2382857142857143, 0.17722657252311147)\n",
            "epoch  10 loss  0.009270644688180514 Train Accuracy & F1 (0.4589642857142857, 0.39528474252078855) Validation Accuracy & F1  (0.38857142857142857, 0.3002946805820666)\n",
            "{'layers': 3, 'hidden_size': 500}\n",
            "epoch  1 loss  0.012374147819621222 Train Accuracy & F1 (0.27967857142857144, 0.2589820772112363) Validation Accuracy & F1  (0.21542857142857144, 0.1579475101253865)\n",
            "epoch  2 loss  0.011864781584058489 Train Accuracy & F1 (0.3043571428571429, 0.252914704438746) Validation Accuracy & F1  (0.224, 0.12489522784888714)\n",
            "epoch  3 loss  0.01138420404280935 Train Accuracy & F1 (0.3298214285714286, 0.27114618227298276) Validation Accuracy & F1  (0.23885714285714285, 0.144870511504943)\n",
            "epoch  4 loss  0.01102437802723476 Train Accuracy & F1 (0.3907857142857143, 0.3459691610202024) Validation Accuracy & F1  (0.28514285714285714, 0.21398214697619838)\n",
            "epoch  5 loss  0.01062159645983151 Train Accuracy & F1 (0.4335357142857143, 0.4166509322609325) Validation Accuracy & F1  (0.31742857142857145, 0.27021226584568525)\n",
            "epoch  6 loss  0.010333772923265185 Train Accuracy & F1 (0.31942857142857145, 0.26630763451617445) Validation Accuracy & F1  (0.24085714285714285, 0.1563715286747581)\n",
            "epoch  7 loss  0.010101954191923142 Train Accuracy & F1 (0.39689285714285716, 0.35279106242581726) Validation Accuracy & F1  (0.304, 0.22805713575195607)\n",
            "epoch  8 loss  0.009850766526801245 Train Accuracy & F1 (0.27, 0.204037320564586) Validation Accuracy & F1  (0.21571428571428572, 0.11511327378284915)\n",
            "epoch  9 loss  0.010642238080501557 Train Accuracy & F1 (0.42942857142857144, 0.4006115626034793) Validation Accuracy & F1  (0.3291428571428571, 0.2694174820563943)\n",
            "epoch  10 loss  0.009723527776343482 Train Accuracy & F1 (0.4288214285714286, 0.38652459034649633) Validation Accuracy & F1  (0.33085714285714285, 0.2808426053559182)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0.20457142857142857, 1, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.22457142857142856, 2, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.2782857142857143, 3, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.32285714285714284, 4, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.37714285714285717, 5, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.39285714285714285, 6, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.422, 7, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.42457142857142854, 8, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.44285714285714284, 9, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.44285714285714284, 9, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.2, 1, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.20114285714285715, 2, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.23485714285714285, 3, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.236, 4, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.36228571428571427, 5, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.4154285714285714, 6, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.4154285714285714, 6, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.4154285714285714, 6, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.45285714285714285, 9, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.45371428571428574, 10, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.1997142857142857, 1, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.20514285714285715, 2, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.2557142857142857, 3, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.3314285714285714, 4, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.3628571428571429, 5, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.402, 6, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.402, 6, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.44771428571428573, 8, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.4697142857142857, 9, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.4734285714285714, 10, {'hidden_size': 300, 'layers': 1}),\n",
              " (0.202, 1, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.21085714285714285, 2, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.29828571428571427, 3, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.29828571428571427, 3, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.344, 5, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.37, 6, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.3871428571428571, 7, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.428, 8, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.44771428571428573, 9, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.47114285714285714, 10, {'hidden_size': 400, 'layers': 1}),\n",
              " (0.198, 1, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.20914285714285713, 2, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.282, 3, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.31142857142857144, 4, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.36628571428571427, 5, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.394, 6, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.394, 6, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.394, 6, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.394, 6, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.4451428571428571, 10, {'hidden_size': 500, 'layers': 1}),\n",
              " (0.206, 1, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.23142857142857143, 2, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.24085714285714285, 3, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.3437142857142857, 4, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.3437142857142857, 4, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.4, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.44057142857142856, 7, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.45457142857142857, 8, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.45457142857142857, 8, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.49314285714285716, 10, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.2022857142857143, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.21942857142857142, 2, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.3028571428571429, 3, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.3028571428571429, 3, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.3028571428571429, 3, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.4288571428571429, 6, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.4288571428571429, 6, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.4288571428571429, 6, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.45485714285714285, 9, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.45485714285714285, 9, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.20514285714285715, 1, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.21142857142857144, 2, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.21971428571428572, 3, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.30657142857142855, 4, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.3545714285714286, 5, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.3545714285714286, 5, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.3545714285714286, 5, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.38285714285714284, 8, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.4377142857142857, 9, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.4377142857142857, 9, {'hidden_size': 300, 'layers': 2}),\n",
              " (0.2062857142857143, 1, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.21485714285714286, 2, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.2662857142857143, 3, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.2785714285714286, 4, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.324, 5, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.324, 5, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.324, 5, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.386, 8, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.386, 8, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.386, 8, {'hidden_size': 400, 'layers': 2}),\n",
              " (0.20142857142857143, 1, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.2322857142857143, 2, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.2737142857142857, 3, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.2737142857142857, 3, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.2737142857142857, 3, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.33171428571428574, 6, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.33171428571428574, 6, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.37314285714285716, 8, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.37314285714285716, 8, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.40285714285714286, 10, {'hidden_size': 500, 'layers': 2}),\n",
              " (0.21171428571428572, 1, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.24371428571428572, 2, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.29514285714285715, 3, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.348, 4, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.348, 4, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.348, 4, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.4197142857142857, 7, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.44257142857142856, 8, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.44257142857142856, 8, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.4462857142857143, 10, {'hidden_size': 100, 'layers': 3}),\n",
              " (0.21228571428571427, 1, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.22428571428571428, 2, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.2631428571428571, 3, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.3565714285714286, 4, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.37085714285714283, 5, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.39371428571428574, 6, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.39371428571428574, 6, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.39371428571428574, 6, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.39371428571428574, 6, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.426, 10, {'hidden_size': 200, 'layers': 3}),\n",
              " (0.21371428571428572, 1, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.2542857142857143, 2, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.258, 3, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.27171428571428574, 4, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.27171428571428574, 4, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.3522857142857143, 6, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.3522857142857143, 6, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.38542857142857145, 8, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.38542857142857145, 8, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.38542857142857145, 8, {'hidden_size': 300, 'layers': 3}),\n",
              " (0.212, 1, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.22314285714285714, 2, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.23857142857142857, 3, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.28685714285714287, 4, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.28685714285714287, 4, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.3231428571428571, 6, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.3474285714285714, 7, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.3474285714285714, 7, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.3474285714285714, 7, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.38857142857142857, 10, {'hidden_size': 400, 'layers': 3}),\n",
              " (0.21542857142857144, 1, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.224, 2, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.23885714285714285, 3, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.28514285714285714, 4, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.31742857142857145, 5, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.31742857142857145, 5, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.31742857142857145, 5, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.31742857142857145, 5, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.3291428571428571, 9, {'hidden_size': 500, 'layers': 3}),\n",
              " (0.33085714285714285, 10, {'hidden_size': 500, 'layers': 3})]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling the hyperparamater optimization for GRU\n",
        "layers_list = [1, 2, 3]\n",
        "hidden_size_list = [100, 200, 300, 400, 500]\n",
        "random_search(hidden_size_list,layers_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjOdqDD80hQh",
        "outputId": "5df8f9c1-b371-4431-eef9-ae543a71ff93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'layers': 1, 'hidden_size': 100}\n",
            "epoch  1 loss  0.012522491071905409 Train Accuracy & F1 (0.21735714285714286, 0.15361606304701242) Validation Accuracy & F1  (0.19542857142857142, 0.06754167280268557)\n",
            "epoch  2 loss  0.012450981387070247 Train Accuracy & F1 (0.24471428571428572, 0.21402334972287748) Validation Accuracy & F1  (0.19485714285714287, 0.06744818503972153)\n",
            "epoch  3 loss  0.012249883941241673 Train Accuracy & F1 (0.28214285714285714, 0.2544283262226445) Validation Accuracy & F1  (0.19514285714285715, 0.06798020554900973)\n",
            "epoch  4 loss  0.011688113033771515 Train Accuracy & F1 (0.3407857142857143, 0.32119285104039097) Validation Accuracy & F1  (0.1957142857142857, 0.06809411879594567)\n",
            "epoch  5 loss  0.011006993519408361 Train Accuracy & F1 (0.39964285714285713, 0.362908521237034) Validation Accuracy & F1  (0.1957142857142857, 0.06805006334620607)\n",
            "epoch  6 loss  0.010523114174604416 Train Accuracy & F1 (0.4205, 0.38319304061201426) Validation Accuracy & F1  (0.196, 0.06860364337266062)\n",
            "epoch  7 loss  0.010224247983523777 Train Accuracy & F1 (0.2007142857142857, 0.06692867410878434) Validation Accuracy & F1  (0.19514285714285715, 0.06531197704996414)\n",
            "epoch  8 loss  0.011714424226965224 Train Accuracy & F1 (0.32735714285714285, 0.2702836527088969) Validation Accuracy & F1  (0.19514285714285715, 0.0663623205395558)\n",
            "epoch  9 loss  0.01057827513558524 Train Accuracy & F1 (0.44589285714285715, 0.4334451026484338) Validation Accuracy & F1  (0.28114285714285714, 0.24268677790347173)\n",
            "epoch  10 loss  0.009611758700438908 Train Accuracy & F1 (0.2991785714285714, 0.23610784542694496) Validation Accuracy & F1  (0.19485714285714287, 0.06527877482651352)\n",
            "{'layers': 1, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012473513049738748 Train Accuracy & F1 (0.22553571428571428, 0.15546366300330547) Validation Accuracy & F1  (0.19485714285714287, 0.06632329044460426)\n",
            "epoch  2 loss  0.012299422992127282 Train Accuracy & F1 (0.2755357142857143, 0.24367686119203125) Validation Accuracy & F1  (0.19485714285714287, 0.06787771541470851)\n",
            "epoch  3 loss  0.011840765135628836 Train Accuracy & F1 (0.3311428571428571, 0.31230078946897466) Validation Accuracy & F1  (0.19542857142857142, 0.06801058907172608)\n",
            "epoch  4 loss  0.011143349294151578 Train Accuracy & F1 (0.3508928571428571, 0.32786247484863096) Validation Accuracy & F1  (0.19514285714285715, 0.06746233280785337)\n",
            "epoch  5 loss  0.010743129640817643 Train Accuracy & F1 (0.20539285714285715, 0.077641357429153) Validation Accuracy & F1  (0.19514285714285715, 0.06531197704996414)\n",
            "epoch  6 loss  0.010458584815263749 Train Accuracy & F1 (0.2840357142857143, 0.20796428829188357) Validation Accuracy & F1  (0.19514285714285715, 0.065837870538415)\n",
            "epoch  7 loss  0.00997741448879242 Train Accuracy & F1 (0.32207142857142856, 0.24484261521582623) Validation Accuracy & F1  (0.19885714285714284, 0.06757427395126295)\n",
            "epoch  8 loss  0.00970826726087502 Train Accuracy & F1 (0.47832142857142856, 0.4650455487381203) Validation Accuracy & F1  (0.20057142857142857, 0.07114869140297972)\n",
            "epoch  9 loss  0.009440810060926846 Train Accuracy & F1 (0.4221785714285714, 0.4147177751845995) Validation Accuracy & F1  (0.19514285714285715, 0.06859968267321395)\n",
            "epoch  10 loss  0.009268255848969733 Train Accuracy & F1 (0.41175, 0.395367648423437) Validation Accuracy & F1  (0.19542857142857142, 0.06761893267219601)\n",
            "{'layers': 2, 'hidden_size': 100}\n",
            "epoch  1 loss  0.012533367936100279 Train Accuracy & F1 (0.19932142857142857, 0.0926094230432611) Validation Accuracy & F1  (0.19342857142857142, 0.06660101666573465)\n",
            "epoch  2 loss  0.012544906667300633 Train Accuracy & F1 (0.2000357142857143, 0.09311240996634006) Validation Accuracy & F1  (0.19342857142857142, 0.06660101666573465)\n",
            "epoch  3 loss  0.012534402051142283 Train Accuracy & F1 (0.2, 0.09433243399893794) Validation Accuracy & F1  (0.19342857142857142, 0.06660101666573465)\n",
            "epoch  4 loss  0.0125076727441379 Train Accuracy & F1 (0.24282142857142858, 0.19593245187675143) Validation Accuracy & F1  (0.19371428571428573, 0.06715461432372408)\n",
            "epoch  5 loss  0.012367079368659429 Train Accuracy & F1 (0.24335714285714286, 0.18411240858104683) Validation Accuracy & F1  (0.19542857142857142, 0.06693594455166998)\n",
            "epoch  6 loss  0.011874455886227745 Train Accuracy & F1 (0.28282142857142856, 0.2296339854556393) Validation Accuracy & F1  (0.19628571428571429, 0.06864886043635311)\n",
            "epoch  7 loss  0.01135859512431281 Train Accuracy & F1 (0.29160714285714284, 0.2421362456523936) Validation Accuracy & F1  (0.19514285714285715, 0.06688861444242712)\n",
            "epoch  8 loss  0.011052553394011089 Train Accuracy & F1 (0.37885714285714284, 0.3253481867199065) Validation Accuracy & F1  (0.19485714285714287, 0.0658635520733211)\n",
            "epoch  9 loss  0.010573006361722946 Train Accuracy & F1 (0.26671428571428574, 0.19649333025224208) Validation Accuracy & F1  (0.19457142857142856, 0.0652142686138377)\n",
            "epoch  10 loss  0.010326141553265708 Train Accuracy & F1 (0.242, 0.14673428121154952) Validation Accuracy & F1  (0.19514285714285715, 0.06531197704996414)\n",
            "{'layers': 2, 'hidden_size': 200}\n",
            "epoch  1 loss  0.012533245184591838 Train Accuracy & F1 (0.20567857142857143, 0.09249574329840546) Validation Accuracy & F1  (0.19485714285714287, 0.06577042966036392)\n",
            "epoch  2 loss  0.012535577088594436 Train Accuracy & F1 (0.21528571428571427, 0.12381906693354572) Validation Accuracy & F1  (0.19428571428571428, 0.06679724769033525)\n",
            "epoch  3 loss  0.012511631054537637 Train Accuracy & F1 (0.23325, 0.18024445766565092) Validation Accuracy & F1  (0.19371428571428573, 0.06619468501212628)\n",
            "epoch  4 loss  0.01240792539715767 Train Accuracy & F1 (0.25657142857142856, 0.20631649267871982) Validation Accuracy & F1  (0.19457142857142856, 0.06676532623685219)\n",
            "epoch  5 loss  0.011989182795797075 Train Accuracy & F1 (0.27164285714285713, 0.2099364974827783) Validation Accuracy & F1  (0.19457142857142856, 0.06616809834370256)\n",
            "epoch  6 loss  0.0115135788832392 Train Accuracy & F1 (0.34282142857142855, 0.318670330045228) Validation Accuracy & F1  (0.19485714285714287, 0.06728323073323288)\n",
            "epoch  7 loss  0.011104518822261265 Train Accuracy & F1 (0.38207142857142856, 0.35270929994906075) Validation Accuracy & F1  (0.19485714285714287, 0.06737163518657)\n",
            "epoch  8 loss  0.010749076298304967 Train Accuracy & F1 (0.39835714285714285, 0.36559944168357744) Validation Accuracy & F1  (0.19514285714285715, 0.0663925394070469)\n",
            "epoch  9 loss  0.010457005900996071 Train Accuracy & F1 (0.42878571428571427, 0.4144586503045212) Validation Accuracy & F1  (0.19542857142857142, 0.06756368069014704)\n",
            "epoch  10 loss  0.01020766061118671 Train Accuracy & F1 (0.3945, 0.3735746942926314) Validation Accuracy & F1  (0.19542857142857142, 0.06700046515628844)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(0.19542857142857142, 1, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.19542857142857142, 1, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.19542857142857142, 1, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.1957142857142857, 4, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.1957142857142857, 4, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.196, 6, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.196, 6, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.196, 6, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.28114285714285714, 9, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.28114285714285714, 9, {'hidden_size': 100, 'layers': 1}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19542857142857142, 3, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19542857142857142, 3, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19542857142857142, 3, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19542857142857142, 3, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19885714285714284, 7, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.20057142857142857, 8, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.20057142857142857, 8, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.20057142857142857, 8, {'hidden_size': 200, 'layers': 1}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19342857142857142, 1, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19371428571428573, 4, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19542857142857142, 5, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19628571428571429, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19628571428571429, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19628571428571429, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19628571428571429, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19628571428571429, 6, {'hidden_size': 100, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19485714285714287, 1, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19514285714285715, 8, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19542857142857142, 9, {'hidden_size': 200, 'layers': 2}),\n",
              " (0.19542857142857142, 9, {'hidden_size': 200, 'layers': 2})]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling the hyperparamater optimization for Ensemble of GRU,LSTM\n",
        "layers_list = [1,2]\n",
        "hidden_size_list = [100,200]\n",
        "random_search(hidden_size_list,layers_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfzBL-SqACdR"
      },
      "source": [
        "# Final model training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtmImTiedPD1"
      },
      "source": [
        "{'layers': 2, 'hidden_size': 100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3gZ52iidVsi",
        "outputId": "73beed8b-4b9d-4624-de76-3d5f9d49bd99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRUmodel(\n",
            "  (embedding): Embedding(53723, 300)\n",
            "  (GRU_layer): GRU(300, 100, num_layers=2)\n",
            "  (activation_fn): Tanh()\n",
            "  (linear_layer): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax_layer): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GRUmodel(\n",
              "  (embedding): Embedding(53723, 300)\n",
              "  (GRU_layer): GRU(300, 100, num_layers=2)\n",
              "  (activation_fn): Tanh()\n",
              "  (linear_layer): Linear(in_features=100, out_features=5, bias=True)\n",
              "  (softmax_layer): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EMBEDDING_SIZE = 300\n",
        "VOCAB_SIZE = len(TEXT.vocab.stoi)\n",
        "NUM_CLASSES = len(LABEL.vocab.stoi)\n",
        "HIDDEN_SIZE = 100\n",
        "NUM_LAYERS = 2\n",
        "\n",
        "\n",
        "model = GRUmodel(EMBEDDING_SIZE, VOCAB_SIZE, NUM_CLASSES, HIDDEN_SIZE, NUM_LAYERS) \n",
        "print(model)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "welTn5PNdfYf"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.01\n",
        "criterion = nn.NLLLoss()\n",
        "# create an instance of SGD with required hyperparameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMEiOVZj2MOz",
        "outputId": "3142b6a9-4798-49a8-db44-25f6724f8675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  1 loss  0.008283695816993713 Train Accuracy & F1 (0.6234285714285714, 0.6003394299877461) Validation Accuracy & F1  (0.524, 0.4845806076611903)\n",
            "epoch  2 loss  0.006178911034549986 Train Accuracy & F1 (0.7830357142857143, 0.7816272535409867) Validation Accuracy & F1  (0.5914285714285714, 0.5850062893863802)\n",
            "epoch  3 loss  0.005233762388782842 Train Accuracy & F1 (0.8058214285714286, 0.8025334131242282) Validation Accuracy & F1  (0.5745714285714286, 0.5648060747426003)\n",
            "epoch  4 loss  0.004621785409748554 Train Accuracy & F1 (0.8279285714285715, 0.8261795274606903) Validation Accuracy & F1  (0.5708571428571428, 0.5646306792226341)\n",
            "epoch  5 loss  0.004181097785277026 Train Accuracy & F1 (0.8375, 0.8356076297073939) Validation Accuracy & F1  (0.5708571428571428, 0.5653740134206102)\n",
            "epoch  6 loss  0.003946723548429353 Train Accuracy & F1 (0.83625, 0.8352716220424211) Validation Accuracy & F1  (0.5525714285714286, 0.5489130315748321)\n",
            "epoch  7 loss  0.003886275543698243 Train Accuracy & F1 (0.7613928571428571, 0.7545604401937671) Validation Accuracy & F1  (0.5211428571428571, 0.5009897312456183)\n",
            "epoch  8 loss  0.004051715592188494 Train Accuracy & F1 (0.7689285714285714, 0.7636348745240358) Validation Accuracy & F1  (0.5242857142857142, 0.5134792580777972)\n",
            "epoch  9 loss  0.0043739428115742544 Train Accuracy & F1 (0.7792142857142857, 0.7790128217548913) Validation Accuracy & F1  (0.5197142857142857, 0.5199908273230504)\n",
            "epoch  10 loss  0.005573781809636524 Train Accuracy & F1 (0.5980714285714286, 0.5903350111156971) Validation Accuracy & F1  (0.4585714285714286, 0.4480928977533802)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists(\"./drive/MyDrive/checkpoint/\"): # check if the directory doesn't exist already\n",
        "    os.mkdir(\"./drive/MyDrive/checkpoint/\")\n",
        "\n",
        "MAX_EPOCHS = 10\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    # train the model for one pass over the data\n",
        "    train_loss = train(train_iter,model,criterion,optimizer,device)  \n",
        "    # compute the training accuracy\n",
        "    train_acc = evaluate(train_iter,model,criterion,device)\n",
        "    # compute the validation accuracy\n",
        "    val_acc = evaluate(val_iter,model,criterion,device)\n",
        "    \n",
        "    # print the loss for every epoch\n",
        "    print('epoch ',epoch+1,'loss ', train_loss,'Train Accuracy & F1',train_acc,'Validation Accuracy & F1 ', val_acc)\n",
        "    \n",
        "    # save model, optimizer, and number of epoch to a dictionary\n",
        "    model_save = {\n",
        "            'epoch': epoch,  # number of epoch\n",
        "            'model_state_dict': model.state_dict(), # model parameters \n",
        "            'optimizer_state_dict': optimizer.state_dict(), # save optimizer \n",
        "            'loss': train_loss # training loss\n",
        "            }\n",
        "    \n",
        "    # use torch.save to store \n",
        "    torch.save(model_save, \"./drive/MyDrive/checkpoint/model_{}.pt\".format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULmS6TpyAkNI",
        "outputId": "6c864c2e-c40b-4c6f-ccc2-bc00bd648d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GRUmodel(\n",
            "  (embedding): Embedding(53723, 300)\n",
            "  (GRU_layer): GRU(300, 100, num_layers=2)\n",
            "  (activation_fn): Tanh()\n",
            "  (linear_layer): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax_layer): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# The best epoch is 2 an we will be generating our predictions based on the best model.\n",
        "\n",
        "EMBEDDING_SIZE = 300\n",
        "VOCAB_SIZE = 53723\n",
        "NUM_CLASSES = len(LABEL.vocab.stoi)\n",
        "HIDDEN_SIZE = 100\n",
        "NUM_LAYERS = 2\n",
        "# define a new model\n",
        "\n",
        "model = GRUmodel(EMBEDDING_SIZE, VOCAB_SIZE, NUM_CLASSES, HIDDEN_SIZE, NUM_LAYERS) \n",
        "\n",
        "# load checkpoint\n",
        "\n",
        "checkpoint = torch.load(\"./drive/MyDrive/checkpoint/model_1.pt\")\n",
        "\n",
        "# assign the parameters of checkpoint to this new model\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# model.to(device)\n",
        "\n",
        "print(model) # can be used for inference or for further training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-qli5ywn-Vfr"
      },
      "outputs": [],
      "source": [
        "## Funtion to generate the predictions.\n",
        "\n",
        "def inference(loader):\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    with torch.no_grad(): # impacts the autograd engine and deactivate it. reduces memory usage and speeds up computation\n",
        "        for batch in loader:\n",
        "            # load the current batch\n",
        "            batch_input = batch.tweet\n",
        "            # forward propagation\n",
        "            # pass the data through the model\n",
        "            model_outputs = model(batch_input)\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(model_outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "\n",
        "    return all_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qjPeIaJ0Dau9"
      },
      "outputs": [],
      "source": [
        "pred_list = inference(val_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Kr3_GsWwhsl"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_list = inference(test_iter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "w89K4BRnD4fW"
      },
      "outputs": [],
      "source": [
        "\n",
        "pred_list = [x.item() for x in pred_list]\n",
        "pred_list = [LABEL.vocab.itos[x] for x in pred_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nyLeskVW2g97"
      },
      "outputs": [],
      "source": [
        "test_list = [x.item() for x in test_list]\n",
        "test_list = [LABEL.vocab.itos[x] for x in test_list]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp7phKVMEdDc"
      },
      "source": [
        "##  Generating Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mP6AQHdgwPsL"
      },
      "outputs": [],
      "source": [
        "def out_prediction(first_name, last_name, prediction_list, dataset, submit_number):\n",
        "    \"\"\"\n",
        "    out_prediction takes three input varibles: first_name, last_name, prediction_list\n",
        "    <first_name>, string, your first name, e.g., Tom\n",
        "    <last_name>, string, your last name, e.g., Smith\n",
        "    <prediction_list>, list of string which includes all your predications of TEST samples\n",
        "                        e.g., ['1star','5star','3star']\n",
        "    <dataset> dev or test\n",
        "    <submit_number> index of your submission\n",
        "                        \n",
        "    Generate a file is named with <yourfirstname>_<yourlastname>_PRED.txt in current directory\n",
        "    \"\"\"\n",
        "    output_file = open(\"{}_{}_{}_{}.txt\".format(first_name,last_name, dataset, submit_number),'w')\n",
        "    for item in prediction_list:\n",
        "        output_file.write(item+\"\\n\")\n",
        "    output_file.close() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHmXQoSuwPsL"
      },
      "source": [
        "A example of using `out_prediction` funtion. You can find a file `Tom_Smith_PRED.txt` in your diretory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tlT98mQuwPsL"
      },
      "outputs": [],
      "source": [
        "out_prediction(\"Varadraj\", \"Poojari\",test_list, \"test\", \"4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps Taken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1. Hyper parameter optimization \n",
        "\n",
        "- Based on results of the hyperparameter optimization, the number of layers chosen are 2 and number of hidden units are 100. \n",
        "\n",
        "- Hyperparamters used :\n",
        "\n",
        "   EMBEDDING_SIZE = 300\n",
        "   \n",
        "   VOCAB_SIZE = len(TEXT.vocab.stoi). # Vocab size used is 10002 as we set max_size to 10000 while creating vocabulary\n",
        "   \n",
        "   NUM_CLASSES = len(LABEL.vocab.stoi)\n",
        "   \n",
        "   HIDDEN_SIZE = 100\n",
        "   \n",
        "   NUM_LAYERS = 2\n",
        "   \n",
        "   \n",
        "2. Strategies attempted :\n",
        "\n",
        "- Tried running three models - GRU, LSTM and CONVNet. Based on the results, it seemed that the GRU model performed the best.\n",
        "- Took the top 10000 words while building vocabulary by adding `max_size = 10000`\n",
        "- Chose embedding size as 300 for the model.\n",
        "- Ran hyperparameter optimization with a small dataset first on all the above mentioned models and then based on the results, ran the model on the complete train set for each of the above model. Tried different values for number of layers, hidden size and learning rate. The best possible parameters that I considered for GRU model based on the results are `num_layers` = 2 and `hidden_size` = 100"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab4_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:571]",
      "language": "python",
      "name": "conda-env-571-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
